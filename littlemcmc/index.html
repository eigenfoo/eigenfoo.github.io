<!doctype html><html lang=en-US><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><link rel="shortcut icon" href=https://www.georgeho.org/favicon.ico><title>`littlemcmc` — A Standalone HMC and NUTS Sampler in Python | George Ho</title><meta name=title content="`littlemcmc` — A Standalone HMC and NUTS Sampler in Python"><meta name=description content="
  

Recently there has been a modularization (or, if you&rsquo;re hip with tech-lingo, an
unbundling)
of Bayesian modelling libraries. Whereas before, probability distributions,
model specification, inference and diagnostics were more or less rolled into one
library, it&rsquo;s becoming more and more realistic to specify a model in one
library, accelerate it using another, perform inference with a third and use a
fourth to visualize the results. (For example, Junpeng Lao has recently had
good success doing
exactly this!)"><meta name=keywords content="bayes,open-source,probabilistic-programming,pymc,python,"><meta property="og:url" content="https://www.georgeho.org/littlemcmc/"><meta property="og:site_name" content="George Ho"><meta property="og:title" content="`littlemcmc` — A Standalone HMC and NUTS Sampler in Python"><meta property="og:description" content="Recently there has been a modularization (or, if you’re hip with tech-lingo, an unbundling) of Bayesian modelling libraries. Whereas before, probability distributions, model specification, inference and diagnostics were more or less rolled into one library, it’s becoming more and more realistic to specify a model in one library, accelerate it using another, perform inference with a third and use a fourth to visualize the results. (For example, Junpeng Lao has recently had good success doing exactly this!)"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="article:section" content="blog"><meta property="article:published_time" content="2020-10-06T00:00:00+00:00"><meta property="article:modified_time" content="2020-10-06T00:00:00+00:00"><meta property="article:tag" content="Bayes"><meta property="article:tag" content="Open-Source"><meta property="article:tag" content="Probabilistic-Programming"><meta property="article:tag" content="Pymc"><meta property="article:tag" content="Python"><meta property="og:image" content="https://www.georgeho.org/assets/images/asterism.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://www.georgeho.org/assets/images/asterism.png"><meta name=twitter:title content="`littlemcmc` — A Standalone HMC and NUTS Sampler in Python"><meta name=twitter:description content="Recently there has been a modularization (or, if you’re hip with tech-lingo, an unbundling) of Bayesian modelling libraries. Whereas before, probability distributions, model specification, inference and diagnostics were more or less rolled into one library, it’s becoming more and more realistic to specify a model in one library, accelerate it using another, perform inference with a third and use a fourth to visualize the results. (For example, Junpeng Lao has recently had good success doing exactly this!)"><meta itemprop=name content="`littlemcmc` — A Standalone HMC and NUTS Sampler in Python"><meta itemprop=description content="Recently there has been a modularization (or, if you’re hip with tech-lingo, an unbundling) of Bayesian modelling libraries. Whereas before, probability distributions, model specification, inference and diagnostics were more or less rolled into one library, it’s becoming more and more realistic to specify a model in one library, accelerate it using another, perform inference with a third and use a fourth to visualize the results. (For example, Junpeng Lao has recently had good success doing exactly this!)"><meta itemprop=datePublished content="2020-10-06T00:00:00+00:00"><meta itemprop=dateModified content="2020-10-06T00:00:00+00:00"><meta itemprop=wordCount content="227"><meta itemprop=image content="https://www.georgeho.org/assets/images/asterism.png"><meta itemprop=keywords content="Bayes,Open-Source,Probabilistic-Programming,Pymc,Python"><meta name=referrer content="no-referrer-when-downgrade"><style>body{font-family:Verdana,sans-serif;margin:auto;padding:20px;max-width:720px;text-align:left;background-color:#fff;word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:#444}h1,h2,h3,h4,h5,h6,strong,b{color:#222}a{color:#3273dc}.title{text-decoration:none;border:0}.title span{font-weight:400}nav a{margin-right:10px}textarea{width:100%;font-size:16px}input{font-size:16px}content{line-height:1.6}table{width:100%}img{max-width:100%}code{padding:2px 5px;background-color:#f2f2f2}pre code{color:#222;display:block;padding:20px;white-space:pre-wrap;font-size:14px}div.highlight pre{background-color:initial;color:initial}div.highlight code{background-color:unset;color:unset}blockquote{border-left:1px solid #999;color:#222;padding-left:20px;font-style:italic}footer{padding:25px;text-align:center}.helptext{color:#777;font-size:small}.errorlist{color:#eba613;font-size:small}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:#8b6fcb}@media(prefers-color-scheme:dark){body{background-color:#333;color:#ddd}h1,h2,h3,h4,h5,h6,strong,b{color:#eee}a{color:#8cc2dd}code{background-color:#777}pre code{color:#ddd}blockquote{color:#ccc}textarea,input{background-color:#252525;color:#ddd}.helptext{color:#aaa}}</style><script type=text/javascript src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script type=text/x-mathjax-config>
  MathJax.Hub.Config({ tex2jax: {inlineMath: [["$", "$"]]} })
</script><link rel=stylesheet media=all href=/assets/fonts/nicholson-gothic.css type=text/css><link rel=stylesheet media=all href=/assets/fonts/triplicate-a.css type=text/css><script type=text/javascript>navigator.appVersion.indexOf("Win")!=-1?document.write('<link rel="stylesheet" type="text/css" media="all" href="/assets/fonts/equity-a.css"/>'):navigator.appVersion.indexOf("Mac")!=-1?navigator.userAgent.match(/iPad/i)!=null?(document.write('<link rel="stylesheet" media="only screen and (max-device-width: 1024px)" href="/assets/fonts/equity-b.css" type="text/css"/>'),document.write('<link rel="stylesheet" media="only screen and (min-device-width: 768px) and (max-device-width: 1024px) and (-webkit-min-device-pixel-ratio: 2)" type="text/css" href="/assets/fonts/equity-a.css"/>')):document.write('<link rel="stylesheet" type="text/css" media="all" href="/assets/fonts/equity-b.css"/>'):document.write('<link rel="stylesheet" type="text/css" media="all" href="/assets/fonts/equity-a.css"/>')</script><style>html{font-size:18px;font-size:min(max(18px,4vw),26px)}content{line-height:1.45}body{max-width:800px;font-family:Equity,times new roman,Palatino,serif;background-color:#fffff8}code{font-family:Triplicate,lucida console,monospace;font-size:85%;background-color:unset}pre code{white-space:pre;overflow-x:auto;font-size:14px;font-size:min(max(12px,2vw),16px);text-size-adjust:100%;-ms-text-size-adjust:100%;-moz-text-size-adjust:100%;-webkit-text-size-adjust:100%}h1,h2,h3,h4,h5,h6{font-family:NicholsonGothic,Verdana,sans-serif;line-height:1.25}h2,h3,h4,h5,h6{margin-top:8%;margin-bottom:-1%}nav{margin-top:3%;margin-bottom:5%}p.wide-embeds{position:relative;left:50%;transform:translate(-50%,0);width:90vw}ul.blog-posts li span{flex:0 0 140px}.revue-form-group,.revue-form-actions{display:inline-block}input[type=email]{font-family:Triplicate,lucida console,monospace;font-size:80%}input[type=submit]{font-family:Equity,times new roman,Palatino,serif;font-size:80%}@media(prefers-color-scheme:dark){body{background-color:#111}}</style></head><body><header><a href=/ class=title><h2>⁂ George Ho</h2></a><nav><a href=/>Home</a>
<a href=/blog>Blog</a>
<a href=/crosswords/>Crosswords</a>
<a href=/work/>Work</a></nav></header><main><h1><code>littlemcmc</code> — A Standalone HMC and NUTS Sampler in Python</h1><p><i><time datetime=2020-10-06 pubdate>2020-10-06</time></i></p><content><center><img src=https://raw.githubusercontent.com/eigenfoo/littlemcmc/master/docs/_static/logo/default-cropped.png alt="LittleMCMC logo"></center><p>Recently there has been a modularization (or, if you&rsquo;re hip with tech-lingo, an
<a href=https://techcrunch.com/2015/04/18/the-unbundling-of-everything/><em>unbundling</em></a>)
of Bayesian modelling libraries. Whereas before, probability distributions,
model specification, inference and diagnostics were more or less rolled into one
library, it&rsquo;s becoming more and more realistic to specify a model in one
library, accelerate it using another, perform inference with a third and use a
fourth to visualize the results. (For example, Junpeng Lao has recently had
<a href=https://twitter.com/junpenglao/status/1309470970223226882>good success</a> doing
exactly this!)</p><p>It&rsquo;s in this spirit of unbundling that the PyMC developers wanted to <a href=https://discourse.pymc.io/t/isolate-nuts-into-a-new-library/3974>spin out
the core HMC and NUTS samplers from PyMC3 into a separate
library</a>.
PyMC3 has a very well-tested and performant Python implementation of HMC and
NUTS, which would be very useful to any users who have their own functions for
computing log-probability and its gradients, and who want to use a lightweight
and reliable sampler.</p><p>So for example, if you&rsquo;re a physical scientist with a Bayesian model who&rsquo;s
written your own functions to compute the log probability and its gradients
(perhaps for performance or interoperability reasons), and need a good MCMC
sampler, then <code>littlemcmc</code> is for you! As long as you can call your functions
from Python, you can use the same HMC or NUTS sampler that&rsquo;s used by the rest of
the PyMC3 community.</p><p>So without further ado: please check out <code>littlemcmc</code>!</p><ul><li><a href=https://github.com/eigenfoo/littlemcmc>GitHub</a></li><li><a href=https://littlemcmc.readthedocs.io/en/latest/>Read the Docs</a></li></ul></content><p><a href=https://www.georgeho.org/blog/bayes/>#Bayes</a>
<a href=https://www.georgeho.org/blog/open-source/>#Open-Source</a>
<a href=https://www.georgeho.org/blog/probabilistic-programming/>#Probabilistic-Programming</a>
<a href=https://www.georgeho.org/blog/pymc/>#Pymc</a>
<a href=https://www.georgeho.org/blog/python/>#Python</a></p></main><footer><form action=https://buttondown.email/api/emails/embed-subscribe/eigenfoo method=post target=popupwindow onsubmit='window.open("https://buttondown.email/eigenfoo","popupwindow")' class=embeddable-buttondown-form><label for=bd-email>Get my (monthly?) blog posts over email:</label><br><input type=email name=email id=bd-email placeholder=your@email.com>
<input type=submit value=Subscribe></form></footer></body></html>
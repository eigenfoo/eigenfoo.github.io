<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>open-source on George Ho</title><link>https://www.georgeho.org/blog/open-source/</link><description>Recent content in open-source on George Ho</description><generator>Hugo -- gohugo.io</generator><language>en-US</language><copyright>Copyright © 2022, George Ho.</copyright><lastBuildDate>Sat, 11 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://www.georgeho.org/blog/open-source/feed.xml" rel="self" type="application/rss+xml"/><item><title>`cryptics.georgeho.org` — A Dataset of Cryptic Crossword Clues</title><link>https://www.georgeho.org/cryptic-clues/</link><pubDate>Sat, 11 Sep 2021 00:00:00 +0000</pubDate><guid>https://www.georgeho.org/cryptic-clues/</guid><description>&lt;p>&lt;code>cryptics.georgeho.org&lt;/code> is a dataset of cryptic crossword clues&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>, collected
from various blogs and publicly available digital archives. I originally
started this project to practice my web scraping and data engineering skills,
but as it&amp;rsquo;s evolved I hope it can be a resource to solvers and constructors of
cryptic crosswords.&lt;/p>
&lt;p>The project scrapes several blogs and digital archives for cryptic crosswords.
Out of these collected web pages, the clues, answers, clue numbers, blogger’s
explanation and commentary, puzzle title and publication date are all parsed
and extracted into a tabular dataset. The result (as of September 2021) is &lt;strong>a
little over half a million clues from cryptic crosswords over the past twelve
years&lt;/strong>, which makes for a rich and peculiar dataset.&lt;/p>
&lt;p>Without further ado, please check out
&lt;a href="https://cryptics.georgeho.org/">&lt;code>cryptics.georgeho.org&lt;/code>&lt;/a>!&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>If you&amp;rsquo;re new to cryptic crosswords, rejoice! A whole new world awaits you! The New Yorker has &lt;a href="https://www.newyorker.com/puzzles-and-games-dept/cryptic-crossword/reintroducing-the-new-yorkers-cryptic-crossword">an excellent introduction to cryptic crosswords&lt;/a>, and Matt Gritzmacher has &lt;a href="https://crosswordlinks.substack.com/">a daily newsletter with links to crosswords&lt;/a>.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>What I Wish Someone Had Told Me About Tensor Computation Libraries</title><link>https://www.georgeho.org/tensor-computation-libraries/</link><pubDate>Tue, 15 Dec 2020 00:00:00 +0000</pubDate><guid>https://www.georgeho.org/tensor-computation-libraries/</guid><description>&lt;p>I get confused with tensor computation libraries (or computational graph libraries, or symbolic
algebra libraries, or whatever they&amp;rsquo;re marketing themselves as these days).&lt;/p>
&lt;p>I was first introduced to PyTorch and TensorFlow and, having no other reference, thought they were
prototypical examples of tensor computation libraries. Then I learnt about Theano &amp;mdash; an older and
less popular project, but different from PyTorch and TensorFlow and better in some meaningful ways.
This was followed by JAX, which seemed to be basically NumPy with more bells and whistles (although
I couldn&amp;rsquo;t articulate what exactly they were). Then came &lt;a href="https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b">the announcement by the PyMC developers
that Theano would have a new JAX
backend&lt;/a>.&lt;/p>
&lt;p>Anyways, this confusion prompted a lot of research and eventually, this blog post.&lt;/p>
&lt;p>Similar to &lt;a href="https://www.georgeho.org/prob-prog-frameworks/">my previous post on the anatomy of probabilistic programming
frameworks&lt;/a>, I’ll first discuss tensor computation
libraries in general &amp;mdash; what they are and how they can differ from one another. Then I&amp;rsquo;ll discuss
some libraries in detail, and finally offer an observation on the future of Theano in the context of
contemporary tensor computation libraries.&lt;/p>
&lt;div>
&lt;h2>Contents&lt;/h2>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#dissecting-tensor-computation-libraries">Dissecting Tensor Computation Libraries&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#tensor-computation-library-----maybe-not-the-best-name">&amp;ldquo;Tensor Computation Library&amp;rdquo; &amp;mdash; Maybe Not The Best Name&lt;/a>&lt;/li>
&lt;li>&lt;a href="#some-differences-between-tensor-computation-libraries">(Some) Differences Between Tensor Computation Libraries&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#a-zoo-of-tensor-computation-libraries">A Zoo of Tensor Computation Libraries&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#pytorchhttpspytorchorg">&lt;a href="https://pytorch.org/">PyTorch&lt;/a>&lt;/a>&lt;/li>
&lt;li>&lt;a href="#jaxhttpsjaxreadthedocsioenlatest">&lt;a href="https://jax.readthedocs.io/en/latest/">JAX&lt;/a>&lt;/a>&lt;/li>
&lt;li>&lt;a href="#theanohttpstheano-pymcreadthedocsioenlatest">&lt;a href="https://theano-pymc.readthedocs.io/en/latest/">Theano&lt;/a>&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#an-observation-on-static-graphs-and-theano">An Observation on Static Graphs and Theano&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/div>
&lt;h2 id="dissecting-tensor-computation-libraries">Dissecting Tensor Computation Libraries&lt;/h2>
&lt;p>First, a characterization: what do tensor computation libraries even do?&lt;/p>
&lt;ol>
&lt;li>They provide ways of specifying and building computational graphs,&lt;/li>
&lt;li>They run the computation itself (duh), but also run &amp;ldquo;related&amp;rdquo; computations that either (a) &lt;em>use
the computational graph&lt;/em>, or (b) operate &lt;em>directly on the computational graph itself&lt;/em>,
&lt;ul>
&lt;li>The most salient example of the former is computing gradients via
&lt;a href="https://arxiv.org/abs/1502.05767">autodifferentiation&lt;/a>,&lt;/li>
&lt;li>A good example of the latter is optimizing the computation itself: think symbolic
simplifications (e.g. &lt;code>xy/x = y&lt;/code>) or modifications for numerical stability (e.g. &lt;a href="https://cs.stackexchange.com/q/68411">&lt;code>log(1 + x)&lt;/code>
for small values of &lt;code>x&lt;/code>&lt;/a>).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>And they provide &amp;ldquo;best execution&amp;rdquo; for the computation: whether it&amp;rsquo;s changing the execution by JIT
(just-in-time) compiling it, by utilizing special hardware (GPUs/TPUs), by vectorizing the
computation, or in any other way.&lt;/li>
&lt;/ol>
&lt;h3 id="tensor-computation-library-----maybe-not-the-best-name">&amp;ldquo;Tensor Computation Library&amp;rdquo; &amp;mdash; Maybe Not The Best Name&lt;/h3>
&lt;p>As an aside: I realize that the name &amp;ldquo;tensor computation library&amp;rdquo; is too broad, and that the
characterization above precludes some libraries that might also justifiably be called &amp;ldquo;tensor
computation libraries&amp;rdquo;. Better names might be &amp;ldquo;graph computation library&amp;rdquo; (although that might get
mixed up with libraries like &lt;a href="https://networkx.org/">&lt;code>networkx&lt;/code>&lt;/a>) or &amp;ldquo;computational graph management
library&amp;rdquo; or even &amp;ldquo;symbolic tensor algebra libraries&amp;rdquo;.&lt;/p>
&lt;p>So for the avoidance of doubt, here is a list of libraries that this blog post is &lt;em>not&lt;/em> about:&lt;/p>
&lt;ul>
&lt;li>NumPy and SciPy
&lt;ul>
&lt;li>These libraries don&amp;rsquo;t have a concept of a computational graph &amp;mdash; they’re more like a toolbox of
functions, called from Python and executed in C or Fortran.&lt;/li>
&lt;li>However, this might be a controversial distinction &amp;mdash; as we’ll see later, JAX also doesn&amp;rsquo;t build
an explicit computational graph either, and I definitely want to include JAX as a &amp;ldquo;tensor
computation library&amp;rdquo;&amp;hellip; ¯\_(ツ)_/¯&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Numba and Cython
&lt;ul>
&lt;li>These libraries provide best execution for code (and in fact some tensor computation libraries,
such as Theano, make good use them), but like NumPy and SciPy, they do not actually manage the
computational graph itself.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Keras, Trax, Flax and PyTorch-Lightning
&lt;ul>
&lt;li>These libraries are high-level wrappers around tensor computation libraries &amp;mdash; they basically
provide abstractions and a user-facing API to utilize tensor computation libraries in a
friendlier way.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="some-differences-between-tensor-computation-libraries">(Some) Differences Between Tensor Computation Libraries&lt;/h3>
&lt;p>Anyways, back to tensor computation libraries.&lt;/p>
&lt;p>All three aforementioned goals are ambitious undertakings with sophisticated solutions, so it
shouldn&amp;rsquo;t be surprising to learn that decisions in pursuit on goal can have implications for (or
even incur a trade-off with!) other goals. Here&amp;rsquo;s a list of common differences along all three axes:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Tensor computation libraries can differ in how they represent the computational graph, and how it
is built.&lt;/p>
&lt;ul>
&lt;li>Static or dynamic graphs: do we first define the graph completely and then inject data to run
(a.k.a. define-and-run), or is the graph defined on-the-fly via the actual forward computation
(a.k.a. define-by-run)?
&lt;ul>
&lt;li>TensorFlow 1.x was (in)famous for its static graphs, which made users feel like they were
&amp;ldquo;working with their computational graph through a keyhole&amp;rdquo;, especially when &lt;a href="https://news.ycombinator.com/item?id=13429355">compared to
PyTorch&amp;rsquo;s dynamic graphs&lt;/a>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Lazy or eager execution: do we evaluate variables as soon as they are defined, or only when a
dependent variable is evaluated? Usually, tensor computation libraries either choose to support
dynamic graphs with eager execution, or static graphs with lazy execution &amp;mdash; for example,
&lt;a href="https://www.tensorflow.org/guide/eager">TensorFlow 2.0 supports both modes&lt;/a>.&lt;/li>
&lt;li>Interestingly, some tensor computation libraries (e.g. &lt;a href="https://thinc.ai/">Thinc&lt;/a>) don&amp;rsquo;t even
construct an explicit computational graph: they represent it as &lt;a href="https://thinc.ai/docs/concept">chained higher-order
functions&lt;/a>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Tensor computation libraries can also differ in what they want to use the computational graph
&lt;em>for&lt;/em> &amp;mdash; for example, are we aiming to do things that basically amount to running the
computational graph in a &amp;ldquo;different mode&amp;rdquo;, or are we aiming to modify the computational graph
itself?&lt;/p>
&lt;ul>
&lt;li>Almost all tensor computation libraries support autodifferentiation in some capacity (either
forward-mode, backward-mode, or both).&lt;/li>
&lt;li>Obviously, how you represent the computational graph and what you want to use it for are very
related questions! For example, if you want to be able to represent aribtrary computation as a
graph, you&amp;rsquo;ll have to handle control flow like if-else statements or for-loops &amp;mdash; this leads
to common gotchas with &lt;a href="https://jax.readthedocs.io/en/latest/notebooks/Common_Gotchas_in_JAX.html#%F0%9F%94%AA-Control-Flow">using Python for-loops in
JAX&lt;/a>
or needing to use &lt;a href="https://discuss.pytorch.org/t/can-you-have-for-loops-in-the-forward-prop/68295">&lt;code>torch.nn.ModuleList&lt;/code> in for-loops with
PyTorch&lt;/a>.&lt;/li>
&lt;li>Some tensor computation libraries (e.g. &lt;a href="https://github.com/Theano/Theano">Theano&lt;/a> and it&amp;rsquo;s
fork, &lt;a href="https://theano-pymc.readthedocs.io/en/latest/index.html">Theano-PyMC&lt;/a>) aim to &lt;a href="https://theano-pymc.readthedocs.io/en/latest/extending/optimization.html">optimize
the computational graph
itself&lt;/a>, for which an
&lt;a href="#an-observation-on-static-graphs-and-theano">explicit graph is necessary&lt;/a>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Finally, tensor computation libraries can also differ in how they execute code.&lt;/p>
&lt;ul>
&lt;li>All tensor computation libraries run on CPU, but the strength of GPU and TPU support is a major
differentiator among tensor computation libraries.&lt;/li>
&lt;li>Another differentiator is how tensor computation libraries compile code to be executed on
hardware. For example, do they use JIT compilation or not? Do they use &amp;ldquo;vanilla&amp;rdquo; C or CUDA
compilers, or &lt;a href="https://tensorflow.google.cn/xla">the XLA compiler for machine-learning specific
code&lt;/a>?&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="a-zoo-of-tensor-computation-libraries">A Zoo of Tensor Computation Libraries&lt;/h2>
&lt;p>Having outlined the basic similarities and differences of tensor computation libraries, I think
it&amp;rsquo;ll be helpful to go through several of the popular libraries as examples. I&amp;rsquo;ve tried to link to
the relevant documentation where possible.&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>&lt;/p>
&lt;h3 id="pytorchhttpspytorchorg">&lt;a href="https://pytorch.org/">PyTorch&lt;/a>&lt;/h3>
&lt;ol>
&lt;li>How is the computational graph represented and built?
&lt;ul>
&lt;li>PyTorch dynamically builds (and eagerly evaluates) an explicit computational graph. For more
detail on how this is done, check out &lt;a href="https://pytorch.org/docs/stable/notes/autograd.html">the PyTorch docs on autograd
mechanics&lt;/a>.&lt;/li>
&lt;li>For more on how PyTorch computational graphs, see &lt;a href="https://jdhao.github.io/2017/11/12/pytorch-computation-graph/">&lt;code>jdhao&lt;/code>&amp;rsquo;s introductory blog post on
computational graphs in
PyTorch&lt;/a>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>What is the computational graph used for?
&lt;ul>
&lt;li>To quote the &lt;a href="https://pytorch.org/docs/stable/index.html">PyTorch docs&lt;/a>, &amp;ldquo;PyTorch is an
optimized tensor library for deep learning using GPUs and CPUs&amp;rdquo; &amp;mdash; as such, the main focus is
on &lt;a href="https://pytorch.org/docs/stable/notes/autograd.html">autodifferentiation&lt;/a>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>How does the library ensure &amp;ldquo;best execution&amp;rdquo; for computation?
&lt;ul>
&lt;li>PyTorch has &lt;a href="https://pytorch.org/docs/stable/notes/cuda.html">native GPU support&lt;/a> via CUDA.&lt;/li>
&lt;li>PyTorch also has support for TPU through projects like
&lt;a href="https://github.com/pytorch/xla">PyTorch/XLA&lt;/a> and
&lt;a href="https://www.pytorchlightning.ai/">PyTorch-Lightning&lt;/a>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h3 id="jaxhttpsjaxreadthedocsioenlatest">&lt;a href="https://jax.readthedocs.io/en/latest/">JAX&lt;/a>&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>How is the computational graph represented and built?&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Instead of building an explicit computational graph to compute gradients, JAX simply supplies a
&lt;code>grad()&lt;/code> that returns the gradient function of any supplied function. As such, there is
technically no concept of a computational graph &amp;mdash; only pure (i.e. stateless and
side-effect-free) functions and their gradients.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://sjmielke.com/jax-purify.htm">Sabrina Mielke summarizes the situation very well&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>PyTorch builds up a graph as you compute the forward pass, and one call to &lt;code>backward()&lt;/code> on
some &amp;ldquo;result&amp;rdquo; node then augments each intermediate node in the graph with the gradient of the
result node with respect to that intermediate node. JAX on the other hand makes you express
your computation as a Python function, and by transforming it with &lt;code>grad()&lt;/code> gives you a
gradient function that you can evaluate like your computation function — but instead of the
output it gives you the gradient of the output with respect to (by default) the first
parameter that your function took as input.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>What is the computational graph used for?&lt;/p>
&lt;ul>
&lt;li>According to the &lt;a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html">JAX quickstart&lt;/a>,
JAX bills itself as &amp;ldquo;NumPy on the CPU, GPU, and TPU, with great automatic differentiation for
high-performance machine learning research&amp;rdquo;. Hence, its focus is heavily on
autodifferentiation.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>How does the library ensure &amp;ldquo;best execution&amp;rdquo; for computation?&lt;/p>
&lt;ul>
&lt;li>
&lt;p>This is best explained by quoting the &lt;a href="https://jax.readthedocs.io/en/latest/notebooks/quickstart.html">JAX quickstart&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>JAX uses XLA to compile and run your NumPy code on [&amp;hellip;] GPUs and TPUs. Compilation happens
under the hood by default, with library calls getting just-in-time compiled and executed. But
JAX even lets you just-in-time compile your own Python functions into XLA-optimized kernels
[&amp;hellip;] Compilation and automatic differentiation can be composed arbitrarily [&amp;hellip;]&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;li>
&lt;p>For more detail on JAX’s four-function API (&lt;code>grad&lt;/code>, &lt;code>jit&lt;/code>, &lt;code>vmap&lt;/code> and &lt;code>pmap&lt;/code>), see
&lt;a href="http://alexminnaar.com/2020/08/15/jax-overview.html">Alex Minaar&amp;rsquo;s overview of how JAX works&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h3 id="theanohttpstheano-pymcreadthedocsioenlatest">&lt;a href="https://theano-pymc.readthedocs.io/en/latest/">Theano&lt;/a>&lt;/h3>
&lt;blockquote>
&lt;p>&lt;strong>Note:&lt;/strong> the &lt;a href="https://github.com/Theano/Theano">original Theano&lt;/a> (maintained by
&lt;a href="https://mila.quebec/en/">MILA&lt;/a>) has been discontinued, and the PyMC developers have forked the
project: &lt;a href="https://github.com/pymc-devs/Theano-PyMC">Theano-PyMC&lt;/a> (soon to be renamed Aesara). I&amp;rsquo;ll
discuss both the original and forked projects below.&lt;/p>
&lt;/blockquote>
&lt;ol>
&lt;li>How is the computational graph represented and built?
&lt;ul>
&lt;li>Theano statically builds (and lazily evaluates) an explicit computational graph.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>What is the computational graph used for?
&lt;ul>
&lt;li>Theano is unique among tensor computation libraries in that it places more emphasis on
reasoning about the computational graph itself. In other words, while Theano has &lt;a href="https://theano-pymc.readthedocs.io/en/latest/library/gradient.html">strong
support for
autodifferentiation&lt;/a>,
running the computation and computing gradients isn&amp;rsquo;t the be-all and end-all: Theano has an
entire module for &lt;a href="https://theano-pymc.readthedocs.io/en/latest/optimizations.html">optimizing the computational graph
itself&lt;/a>, and makes it fairly
straightforward to compile the Theano graph to different computational backends (by default,
Theano compiles to C or CUDA, but it’s straightforward to compile to JAX).&lt;/li>
&lt;li>Theano is often remembered as a library for deep learning research, but it’s so much more than
that!&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>How does the library ensure &amp;ldquo;best execution&amp;rdquo; for computation?
&lt;ul>
&lt;li>The original Theano used the GCC C compiler for CPU computation, and the NVCC CUDA compiler for
GPU computation.&lt;/li>
&lt;li>The Theano-PyMC fork project &lt;a href="https://pymc-devs.medium.com/the-future-of-pymc3-or-theano-is-dead-long-live-theano-d8005f8a0e9b">will use JAX as a
backend&lt;/a>,
which can utilize CPUs, GPUs and TPUs as available.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h2 id="an-observation-on-static-graphs-and-theano">An Observation on Static Graphs and Theano&lt;/h2>
&lt;p>Finally, a quick observation on static graphs and the niche that Theano fills that other tensor
computation libraries do not. I had huge help from &lt;a href="https://twiecki.io/">Thomas Wiecki&lt;/a> and
&lt;a href="https://brandonwillard.github.io/">Brandon Willard&lt;/a> with this section.&lt;/p>
&lt;p>There&amp;rsquo;s been a consistent movement in most tensor computation libraries away from static graphs (or
more precisely, statically &lt;em>built&lt;/em> graphs): PyTorch and TensorFlow 2 both support dynamically
generated graphs by default, and JAX forgoes an explicit computational graph entirely.&lt;/p>
&lt;p>This movement is understandable &amp;mdash; building the computational graph dynamically matches people&amp;rsquo;s
programming intuition much better. When I write &lt;code>z = x + y&lt;/code>, I don&amp;rsquo;t mean &lt;em>&amp;ldquo;I want to register a sum
operation with two inputs, which is waiting for data to be injected&amp;rdquo;&lt;/em> &amp;mdash; I mean &lt;em>&amp;ldquo;I want to compute
the sum of &lt;code>x&lt;/code> and &lt;code>y&lt;/code>&amp;rdquo;.&lt;/em> The extra layer of indirection is not helpful to most users, who just want
to run their tensor computation at some reasonable speed.&lt;/p>
&lt;p>So let me speak in defence of statically built graphs.&lt;/p>
&lt;p>Having an explicit representation of the computational graph is immensely useful for certain things,
even if it makes the graph harder to work with. You can modify the graph (e.g. graph optimizations,
simplifications and rewriting), and you can reason about and analyze the graph. Having the
computation as an actual &lt;em>object&lt;/em> helps immeasurably for tasks where you need to think about the
computation itself, instead of just blindly running it.&lt;/p>
&lt;p>On the other hand, with dynamically generated graphs, the computational graph is never actually
defined anywhere: the computation is traced out on the fly and behind the scene. You can no longer
do anything interesting with the computational graph: for example, if the computation is slow, you
can&amp;rsquo;t reason about &lt;em>what&lt;/em> parts of the graph are slow. The end result is that you basically have to
hope that the framework internals are doing the right things, which they might not!&lt;/p>
&lt;p>This is the niche that Theano (or rather, Theano-PyMC/Aesara) fills that other contemporary tensor
computation libraries do not: the promise is that if you take the time to specify your computation
up front and all at once, Theano can optimize the living daylight out of your computation &amp;mdash; whether
by graph manipulation, efficient compilation or something else entirely &amp;mdash; and that this is something
you would only need to do once.&lt;/p>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>Some readers will notice the conspicuous lack of TensorFlow from this list - its exclusion isn&amp;rsquo;t out of malice, merely a lack of time and effort to do the necessary research to do it justice. Sorry.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>`littlemcmc` — A Standalone HMC and NUTS Sampler in Python</title><link>https://www.georgeho.org/littlemcmc/</link><pubDate>Tue, 06 Oct 2020 00:00:00 +0000</pubDate><guid>https://www.georgeho.org/littlemcmc/</guid><description>&lt;center>
&lt;img
src="https://raw.githubusercontent.com/eigenfoo/littlemcmc/master/docs/_static/logo/default-cropped.png"
alt="LittleMCMC logo">
&lt;/center>
&lt;p>Recently there has been a modularization (or, if you&amp;rsquo;re hip with tech-lingo, an
&lt;a href="https://techcrunch.com/2015/04/18/the-unbundling-of-everything/">&lt;em>unbundling&lt;/em>&lt;/a>)
of Bayesian modelling libraries. Whereas before, probability distributions,
model specification, inference and diagnostics were more or less rolled into one
library, it&amp;rsquo;s becoming more and more realistic to specify a model in one
library, accelerate it using another, perform inference with a third and use a
fourth to visualize the results. (For example, Junpeng Lao has recently had
&lt;a href="https://twitter.com/junpenglao/status/1309470970223226882">good success&lt;/a> doing
exactly this!)&lt;/p>
&lt;p>It&amp;rsquo;s in this spirit of unbundling that the PyMC developers wanted to &lt;a href="https://discourse.pymc.io/t/isolate-nuts-into-a-new-library/3974">spin out
the core HMC and NUTS samplers from PyMC3 into a separate
library&lt;/a>.
PyMC3 has a very well-tested and performant Python implementation of HMC and
NUTS, which would be very useful to any users who have their own functions for
computing log-probability and its gradients, and who want to use a lightweight
and reliable sampler.&lt;/p>
&lt;p>So for example, if you&amp;rsquo;re a physical scientist with a Bayesian model who&amp;rsquo;s
written your own functions to compute the log probability and its gradients
(perhaps for performance or interoperability reasons), and need a good MCMC
sampler, then &lt;code>littlemcmc&lt;/code> is for you! As long as you can call your functions
from Python, you can use the same HMC or NUTS sampler that&amp;rsquo;s used by the rest of
the PyMC3 community.&lt;/p>
&lt;p>So without further ado: please check out &lt;code>littlemcmc&lt;/code>!&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/eigenfoo/littlemcmc">GitHub&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://littlemcmc.readthedocs.io/en/latest/">Read the Docs&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Benchmarks for Mass Matrix Adaptation</title><link>https://www.georgeho.org/mass-matrix-benchmarks/</link><pubDate>Sat, 14 Dec 2019 00:00:00 +0000</pubDate><guid>https://www.georgeho.org/mass-matrix-benchmarks/</guid><description>&lt;p>I was lucky enough to be invited to attend the &lt;a href="https://gradientretreat.com/">Gradient
Retreat&lt;/a> earlier this month. It was an entire week
on a beautiful island with some amazingly intelligent Bayesians, and no demands
on my time other than the self-set (and admittedly vague) goal of contributing
to probabilistic programming in some way.&lt;/p>
&lt;p>I initially tried to implement mass matrix adaptation in Tensorflow Probability,
but I quickly readjusted my goals to something more achievable: running some
benchmarks with tuning in Hamiltonian Monte Carlo (HMC).&lt;/p>
&lt;figure>
&lt;a href="https://www.georgeho.org/assets/images/galiano.jpg">&lt;img src="https://www.georgeho.org/assets/images/galiano.jpg" alt="A view of a forest on Galiano Island">&lt;/a>
&lt;a href="https://www.georgeho.org/assets/images/galiano2.jpg">&lt;img src="https://www.georgeho.org/assets/images/galiano2.jpg" alt="The view from a bluff on Galiano Island">&lt;/a>
&lt;figcaption>Pictures from Galiano Island.&lt;/figcaption>
&lt;/figure>
&lt;p>A quick rundown for those unfamiliar: &lt;em>tuning&lt;/em> is what happens before sampling,
during which the goal is not to actually draw samples, but to &lt;em>prepare&lt;/em> to draw
samples&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. For HMC and its variants, this means estimating HMC parameters such
as the step size, integration time and mass matrix&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>, the last of which is
basically the covariance matrix of the model parameters. Because my life is
finite (and I assume everybody else&amp;rsquo;s is too), I limited myself to mass matrix
adaptation.&lt;/p>
&lt;p>(If you&amp;rsquo;re still uncertain about the details of tuning or mass matrix
adaptation, check out &lt;a href="https://colcarroll.github.io/hmc_tuning_talk/">Colin Carroll&amp;rsquo;s essay on HMC
tuning&lt;/a> or the &lt;a href="https://mc-stan.org/docs/2_20/reference-manual/hmc-algorithm-parameters.html">Stan reference
manual on HMC
parameters&lt;/a>:
I don&amp;rsquo;t explain many more concepts in the rest of this post.)&lt;/p>
&lt;p>The interesting thing about tuning is that there are no rules: there are no
asymptotic guarantees we can rely on and no mathematical results to which we can
turn for enlightened inspiration. The only thing we care about is obtaining a
decent estimate of the mass matrix, and preferably quickly.&lt;/p>
&lt;p>Accompanying this lack of understanding of mass matrix adaptation is an
commensurate lack of (apparent) scientific inquiry — there is scant literature
to look to, and for open source developers, there is little prior art to draw
from when writing new implementations of HMC!&lt;/p>
&lt;p>So I decided to do some empirical legwork and benchmark various methods of mass
matrix adaptation. Here are the questions I was interested in answering:&lt;/p>
&lt;ol>
&lt;li>Is the assumption that the mass matrix is diagonal (in other words, assume
that all parameters are uncorrelated) a good assumption to make? What are
the implications of this assumption for the tuning time, and the number of
effective samples per second?&lt;/li>
&lt;li>Does the tuning schedule (i.e. the sizes of the adaptation windows) make a
big difference? Specifically, should we have a schedule of constant
adaptation windows, or an &amp;ldquo;expanding schedule&amp;rdquo; of exponentially growing
adaptation windows?&lt;/li>
&lt;li>Besides assuming the mass matrix is diagonal, are there any other ways of
simplifying mass matrix adaptation? For example, could we approximate the
mass matrix as low rank?&lt;/li>
&lt;/ol>
&lt;p>I benchmarked five different mass matrix adaptation methods:&lt;/p>
&lt;ol>
&lt;li>A diagonal mass matrix (&lt;code>diag&lt;/code>)&lt;/li>
&lt;li>A full (a.k.a. dense) mass matrix (&lt;code>full&lt;/code>)&lt;/li>
&lt;li>A diagonal mass matrix adapted on an expanding schedule (&lt;code>diag_exp&lt;/code>)&lt;/li>
&lt;li>A full mass matrix adapted on an expanding schedule (&lt;code>diag_exp&lt;/code>)&lt;/li>
&lt;li>A low-rank approximation to the mass matrix using &lt;a href="https://github.com/aseyboldt/covadapt">Adrian Seyboldt&amp;rsquo;s &lt;code>covadapt&lt;/code> library&lt;/a>.&lt;/li>
&lt;/ol>
&lt;p>I benchmarked these adaptation methods against six models:&lt;/p>
&lt;ol>
&lt;li>A 100-dimensional multivariate normal with a non-diagonal covariance matrix (&lt;code>mvnormal&lt;/code>)&lt;/li>
&lt;li>A 100-dimensional multivariate normal with a low-rank covariance matrix (&lt;code>lrnormal&lt;/code>)&lt;/li>
&lt;li>A &lt;a href="https://docs.pymc.io/notebooks/stochastic_volatility.html">stochastic volatility model&lt;/a> (&lt;code>stoch_vol&lt;/code>)&lt;/li>
&lt;li>The &lt;a href="https://docs.pymc.io/notebooks/Diagnosing_biased_Inference_with_Divergences.html#The-Eight-Schools-Model">eight schools model&lt;/a> (&lt;code>eight&lt;/code>)&lt;/li>
&lt;li>The &lt;a href="https://docs.pymc.io/notebooks/hierarchical_partial_pooling.html">PyMC3 baseball model&lt;/a> (&lt;code>baseball&lt;/code>)&lt;/li>
&lt;li>A &lt;a href="https://docs.pymc.io/notebooks/GP-SparseApprox.html#Examples">sparse Gaussian process approximation&lt;/a> (&lt;code>gp&lt;/code>)&lt;/li>
&lt;/ol>
&lt;p>Without further ado, the main results are shown below. Afterwards, I make some
general observations on the benchmarks, and finally I describe various
shortcomings of my experimental setup (which, if I were more optimistic, I would
call &amp;ldquo;directions for further work&amp;rdquo;).&lt;/p>
&lt;h3 id="tuning-times">Tuning Times&lt;/h3>
&lt;p>This tabulates the tuning time, in seconds, of each adaptation method for each
model. Lower is better. The lowest tuning time for each model is shown in bold
italics.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>mvnormal&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>lrnormal&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>stoch_vol&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>gp&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>eight&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>baseball&lt;/code>&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>diag&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">365.34&lt;/td>
&lt;td style="text-align:right">340.10&lt;/td>
&lt;td style="text-align:right">239.59&lt;/td>
&lt;td style="text-align:right">18.47&lt;/td>
&lt;td style="text-align:right">2.92&lt;/td>
&lt;td style="text-align:right">5.32&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>full&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>8.29&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">364.07&lt;/td>
&lt;td style="text-align:right">904.95&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>14.24&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>2.91&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>4.93&lt;/strong>&lt;/em>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>diag_exp&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">358.50&lt;/td>
&lt;td style="text-align:right">360.91&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>219.65&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">16.25&lt;/td>
&lt;td style="text-align:right">3.05&lt;/td>
&lt;td style="text-align:right">5.08&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>full_exp&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">8.46&lt;/td>
&lt;td style="text-align:right">142.20&lt;/td>
&lt;td style="text-align:right">686.58&lt;/td>
&lt;td style="text-align:right">14.87&lt;/td>
&lt;td style="text-align:right">3.21&lt;/td>
&lt;td style="text-align:right">6.04&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>covadapt&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">386.13&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>89.92&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">398.08&lt;/td>
&lt;td style="text-align:right">N/A&lt;/td>
&lt;td style="text-align:right">N/A&lt;/td>
&lt;td style="text-align:right">N/A&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h3 id="effective-samples-per-second">Effective Samples per Second&lt;/h3>
&lt;p>This tabulates the number of effective samples drawn by each adaptation method
for each model. Higher is better. The highest numbers of effective samples per
second is shown in bold italics.&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>mvnormal&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>lrnormal&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>stoch_vol&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>gp&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>eight&lt;/code>&lt;/strong>&lt;/th>
&lt;th style="text-align:right">&lt;strong>&lt;code>baseball&lt;/code>&lt;/strong>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>diag&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">0.02&lt;/td>
&lt;td style="text-align:right">1.55&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>11.22&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">65.36&lt;/td>
&lt;td style="text-align:right">761.82&lt;/td>
&lt;td style="text-align:right">455.23&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>full&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">1.73&lt;/td>
&lt;td style="text-align:right">0.01&lt;/td>
&lt;td style="text-align:right">6.71&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>106.30&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>840.77&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>495.93&lt;/strong>&lt;/em>&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>diag_exp&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">0.02&lt;/td>
&lt;td style="text-align:right">1.51&lt;/td>
&lt;td style="text-align:right">9.79&lt;/td>
&lt;td style="text-align:right">59.89&lt;/td>
&lt;td style="text-align:right">640.90&lt;/td>
&lt;td style="text-align:right">336.71&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>full_exp&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>1,799.11&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">&lt;em>&lt;strong>1,753.65&lt;/strong>&lt;/em>&lt;/td>
&lt;td style="text-align:right">0.16&lt;/td>
&lt;td style="text-align:right">101.99&lt;/td>
&lt;td style="text-align:right">618.28&lt;/td>
&lt;td style="text-align:right">360.14&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">&lt;strong>&lt;code>covadapt&lt;/code>&lt;/strong>&lt;/td>
&lt;td style="text-align:right">0.02&lt;/td>
&lt;td style="text-align:right">693.87&lt;/td>
&lt;td style="text-align:right">5.71&lt;/td>
&lt;td style="text-align:right">N/A&lt;/td>
&lt;td style="text-align:right">N/A&lt;/td>
&lt;td style="text-align:right">N/A&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;h2 id="observations">Observations&lt;/h2>
&lt;blockquote>
&lt;p>&lt;strong>tldr:&lt;/strong> As is typical with these sorts of things, no one adaptation method
uniformly outperforms the others.&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>A full mass matrix can provide significant improvements over a diagonal mass
matrix for both the tuning time and the number of effective samples per
second. This improvement can sometimes go up to two orders of magnitude!
&lt;ul>
&lt;li>This is most noticeable in the &lt;code>mvnormal&lt;/code> model, with heavily correlated
parameters.&lt;/li>
&lt;li>Happily, my benchmarks are not the only instance of full mass matrices
outperforming diagonal ones: &lt;a href="https://dfm.io/posts/pymc3-mass-matrix/">Dan Foreman-Mackey demonstrated something
similar in one of his blog posts&lt;/a>.&lt;/li>
&lt;li>However, in models with less extreme correlations among parameters, this
advantage shrinks significantly (although it doesn&amp;rsquo;t go away entirely).
Full matrices can also take longer to tune. You can see this in the baseball
or eight schools model.&lt;/li>
&lt;li>Nevertheless, full mass matrices never seem to perform egregiously &lt;em>worse&lt;/em>
than diagonal mass matrices. This makes sense theoretically: a full mass
matrix can be estimated to be diagonal (at the cost of a quadratic memory
requirement as opposed to linear), but not vice versa.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>Having an expanding schedule for tuning can sometimes give better performance,
but nowhere near as significant as the difference between diagonal and full
matrices. This difference is most noticeable for the &lt;code>mvnormal&lt;/code> and &lt;code>lrnormal&lt;/code>
models (probably because these models have a constant covariance matrix and so
more careful estimates using expanding windows can provide much better
sampling).&lt;/li>
&lt;li>I suspect the number of effective samples per second for a full mass matrix on
the &lt;code>lrnormal&lt;/code> model (0.01 effective samples per second) is a mistake (or
some other computational fluke): it looks way too low to be reasonable.&lt;/li>
&lt;li>I&amp;rsquo;m also surprised that &lt;code>full_exp&lt;/code> does really badly (in terms of effective
samples per second) on the &lt;code>stoch_vol&lt;/code> model, despite &lt;code>full&lt;/code> doing decently
well! This is either a fluke, or a really interesting phenomenon to dig in to.&lt;/li>
&lt;li>&lt;code>covadapt&lt;/code> seems to run into some numerical difficulties? While running these
benchmarks I ran into an inscrutable and non-reproducible
&lt;a href="https://stackoverflow.com/q/18436667">&lt;code>ArpackError&lt;/code>&lt;/a> from SciPy.&lt;/li>
&lt;/ul>
&lt;h2 id="experimental-setup">Experimental Setup&lt;/h2>
&lt;ul>
&lt;li>All samplers were run for 2000 tuning steps and 1000 sampling steps. This is
unusually high, but is necessary for &lt;code>covadapt&lt;/code> to work well, and I wanted to
use the same number of iterations across all the benchmarks.&lt;/li>
&lt;li>My expanding schedule is as follows: the first adaptation window is 100
iterations, and each subsequent window is 1.005 times the previous window.
These numbers give 20 updates within 2000 iterations, while maintaining an
exponentially increasing adaptation window size.&lt;/li>
&lt;li>I didn&amp;rsquo;t run &lt;code>covadapt&lt;/code> for models with fewer than 100 model parameters.
With so few parameters, there&amp;rsquo;s no need to approximate a mass matrix as
low-rank: you can just estimate the full mass matrix!&lt;/li>
&lt;li>I set &lt;code>target_accept&lt;/code> (a.k.a. &lt;code>adapt_delta&lt;/code> to Stan users) to 0.9 to make all
divergences go away.&lt;/li>
&lt;li>All of these numbers were collected by sampling once per model per adaptation
method (yes only once, sorry) in PyMC3, running on my MacBook Pro.&lt;/li>
&lt;/ul>
&lt;h2 id="shortcomings">Shortcomings&lt;/h2>
&lt;ul>
&lt;li>In some sense comparing tuning times is not a fair comparison: it&amp;rsquo;s possible
that some mass matrix estimates converge quicker than others, and so comparing
their tuning times is essentially penalizing these methods for converging
faster than others.&lt;/li>
&lt;li>It&amp;rsquo;s also possible that my expanding schedule for the adaptation windows just
sucks! There&amp;rsquo;s no reason why the first window needs to be 100 iterations, or
why 1.005 should be a good multiplier. It looks like Stan &lt;a href="https://github.com/stan-dev/stan/blob/736311d88e99b997f5b902409752fb29d6ec0def/src/stan/mcmc/windowed_adaptation.hpp#L95">doubles their
adaptation window
sizes&lt;/a>
during warmup.&lt;/li>
&lt;li>These benchmarks are done only for very basic toy models: I should test more
extensively on more models that people in The Real World™ use.&lt;/li>
&lt;li>If you are interested in taking these benchmarks further (or perhaps just want
to fact-check me on my results), the code is &lt;a href="https://github.com/eigenfoo/mass-matrix-benchmarks">sitting in this GitHub
repository&lt;/a>&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>.&lt;/li>
&lt;/ul>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>It&amp;rsquo;s good to point out that mass matrix adaptation is to make sampling
more efficient, not more valid. Theoretically, any mass matrix would work,
but a good one (i.e. a good estimate of the covariance matrix of the model
parameters) could sample orders of magnitudes more efficiently.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>…uh, &lt;em>&lt;em>sweats and looks around nervously for differential geometers&lt;/em>&lt;/em>
more formally called the &lt;em>metric&lt;/em>…&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>There are some violin plots lying around in the notebook, a relic from a
time when I thought that I would have the patience to run each model and
adaptation method multiple times.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Introducing `stan-vim`</title><link>https://www.georgeho.org/stan-vim/</link><pubDate>Mon, 11 Nov 2019 00:00:00 +0000</pubDate><guid>https://www.georgeho.org/stan-vim/</guid><description>&lt;center>
&lt;img
src="https://www.georgeho.org/assets/images/stan-logo.png"
alt="Stan logo">
&lt;/center>
&lt;p>I made a Vim plugin for Stan!&lt;/p>
&lt;p>I&amp;rsquo;ve been reading and writing a lot of Stan lately, but mainly in barebones text
editors (or even just by &lt;code>cat&lt;/code>ing out the file), so I had to make do with none
of the creature comforts of my favorite text editor, Vim.&lt;/p>
&lt;p>But I also wasn&amp;rsquo;t happy with the syntax highlighting provided by
&lt;a href="https://github.com/maverickg/stan.vim">existing&lt;/a>
&lt;a href="https://github.com/mdlerch/mc-stan.vim">Vim&lt;/a>
&lt;a href="https://github.com/ssp3nc3r/stan-syntax-vim">plugins&lt;/a> (and they also looked out
of date and thinly maintained&amp;hellip;), so I just went ahead and learnt a truckload
of Vimscript&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>.&lt;/p>
&lt;p>Check out the plugin! You can find installation instructions
&lt;a href="https://github.com/eigenfoo/stan-vim#installation">here&lt;/a> and documentation
&lt;a href="https://github.com/eigenfoo/stan-vim#documentation">here&lt;/a>. Screenshots of
syntax highlighting and projects links are below.&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/eigenfoo/stan-vim">GitHub&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://vimawesome.com/plugin/stan-vim-is-written-on">VimAwesome&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.vim.org/scripts/script.php?script_id=5835">Vim Online&lt;/a>&lt;/li>
&lt;/ul>
&lt;figure>
&lt;a href="https://raw.githubusercontent.com/eigenfoo/stan-vim/master/screenshots/screenshot0.png">&lt;img src="https://raw.githubusercontent.com/eigenfoo/stan-vim/master/screenshots/screenshot0.png" alt="Screenshot of a Stan model in stan-vim">&lt;/a>
&lt;a href="https://raw.githubusercontent.com/eigenfoo/stan-vim/master/screenshots/screenshot1.png">&lt;img src="https://raw.githubusercontent.com/eigenfoo/stan-vim/master/screenshots/screenshot1.png" alt="Screenshot of the stan-vim documentation">&lt;/a>
&lt;a href="https://raw.githubusercontent.com/eigenfoo/stan-vim/master/screenshots/screenshot2.png">&lt;img src="https://raw.githubusercontent.com/eigenfoo/stan-vim/master/screenshots/screenshot2.png" alt="Screenshot of another Stan model in stan-vim">&lt;/a>
&lt;figcaption>Screenshots of &lt;code>stan-vim&lt;/code> syntax highlighting.&lt;/figcaption>
&lt;/figure>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>As it turns out, &lt;a href="https://www.reddit.com/r/vim/comments/54224o/why_is_there_so_much_hate_for_vimscript/">Vimscript is a very not-good
language&lt;/a>.
This is probably the last Vim plugin I write.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Anatomy of a Probabilistic Programming Framework</title><link>https://www.georgeho.org/prob-prog-frameworks/</link><pubDate>Mon, 30 Sep 2019 00:00:00 +0000</pubDate><guid>https://www.georgeho.org/prob-prog-frameworks/</guid><description>&lt;p>Recently, the PyMC4 developers &lt;a href="https://openreview.net/forum?id=rkgzj5Za8H">submitted an
abstract&lt;/a> to the &lt;a href="https://program-transformations.github.io/">&lt;em>Program Transformations
for Machine Learning&lt;/em> NeurIPS workshop&lt;/a>. I
realized that despite knowing a thing or two about Bayesian modelling, I don&amp;rsquo;t
understand how probabilistic programming frameworks are structured, and therefore
couldn&amp;rsquo;t appreciate the sophisticated design work going into PyMC4. So I trawled through
papers, documentation and source code&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> of various open-source probabilistic
programming frameworks, and this is what I&amp;rsquo;ve managed to take away from it.&lt;/p>
&lt;p>I assume you know a fair bit about probabilistic programming and Bayesian modelling, and
are familiar with the big players in the probabilistic programming world. If you&amp;rsquo;re
unsure, you can &lt;a href="https://www.georgeho.org/bayesian-inference-reading/">read up here&lt;/a>.&lt;/p>
&lt;div>
&lt;h2>Contents&lt;/h2>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#dissecting-probabilistic-programming-frameworks">Dissecting Probabilistic Programming Frameworks&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#specifying-the-model-languageapi">Specifying the model: language/API&lt;/a>&lt;/li>
&lt;li>&lt;a href="#building-the-model-density-distributions-and-transformations">Building the model density: distributions and transformations&lt;/a>&lt;/li>
&lt;li>&lt;a href="#computing-the-posterior-inference-algorithm">Computing the posterior: inference algorithm&lt;/a>&lt;/li>
&lt;li>&lt;a href="#computing-the-mode-optimizer">Computing the mode: optimizer&lt;/a>&lt;/li>
&lt;li>&lt;a href="#computing-gradients-autodifferentiation">Computing gradients: autodifferentiation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#monitoring-inference-diagnostics">Monitoring inference: diagnostics&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#a-zoo-of-probabilistic-programming-frameworks">A Zoo of Probabilistic Programming Frameworks&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#stan">Stan&lt;/a>&lt;/li>
&lt;li>&lt;a href="#tensorflow-probability-aka-tfp">TensorFlow Probability (a.k.a. TFP)&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pymc3">PyMC3&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pymc4">PyMC4&lt;/a>&lt;/li>
&lt;li>&lt;a href="#pyro">Pyro&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/div>
&lt;h2 id="dissecting-probabilistic-programming-frameworks">Dissecting Probabilistic Programming Frameworks&lt;/h2>
&lt;p>A probabilistic programming framework needs to provide six things:&lt;/p>
&lt;ol>
&lt;li>A language or API for users to specify a model&lt;/li>
&lt;li>A library of probability distributions and transformations to build the posterior
density&lt;/li>
&lt;li>At least one inference algorithm, which either draws samples from the posterior (in
the case of Markov Chain Monte Carlo, MCMC) or computes some approximation of it (in
the case of variational inference, VI)&lt;/li>
&lt;li>At least one optimizer, which can compute the mode of the posterior density&lt;/li>
&lt;li>An autodifferentiation library to compute gradients required by the inference
algorithm and optimizer&lt;/li>
&lt;li>A suite of diagnostics to monitor and analyze the quality of inference&lt;/li>
&lt;/ol>
&lt;p>These six pieces come together like so:&lt;/p>
&lt;p>&lt;img src="https://www.georgeho.org/assets/images/prob-prog-flowchart.png" alt="Flowchart illustrating the structure of a probabilistic programmingframeworks">&lt;/p>
&lt;p>Let&amp;rsquo;s break this down one by one.&lt;/p>
&lt;h3 id="specifying-the-model-languageapi">Specifying the model: language/API&lt;/h3>
&lt;p>This is what users will use to specify their models. Most frameworks will let users
write in some existing programming language and call the framework&amp;rsquo;s functions and
classes, but &lt;del>some others&lt;/del> — why don&amp;rsquo;t I just say it — Stan rolls their own
domain-specific language.&lt;/p>
&lt;p>The main question here is what language you think is best for users to specify models
in: any sufficiently popular host language (such as Python) will reduce the learning
curve for users and make the framework easier to develop and maintain, but a creating
your own language allows you to introduce helpful abstractions for your framework&amp;rsquo;s
particular use case (as &lt;a href="https://mc-stan.org/docs/2_20/reference-manual/blocks-chapter.html">Stan
does&lt;/a>, for example).&lt;/p>
&lt;p>At this point I should point out the non-universal, Python bias in this post: there are
plenty of interesting non-Python probabilistic programming frameworks out there (e.g.
&lt;a href="https://greta-stats.org/">Greta&lt;/a> in R, &lt;a href="https://turing.ml/dev/">Turing&lt;/a> and
&lt;a href="https://www.gen.dev/">Gen&lt;/a> in Julia, &lt;a href="https://github.com/p2t2/figaro">Figaro&lt;/a> and
&lt;a href="https://github.com/stripe/rainier">Rainier&lt;/a> in Scala), as well as universal
probabilistic programming systems&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup> (e.g.
&lt;a href="http://probcomp.csail.mit.edu/software/venture/">Venture&lt;/a> from MIT,
&lt;a href="https://probprog.github.io/anglican/index.html">Angelican&lt;/a> from Oxford)&lt;sup id="fnref:3">&lt;a href="#fn:3" class="footnote-ref" role="doc-noteref">3&lt;/a>&lt;/sup>. I just
don&amp;rsquo;t know anything about any of them.&lt;/p>
&lt;h3 id="building-the-model-density-distributions-and-transformations">Building the model density: distributions and transformations&lt;/h3>
&lt;p>These are what the user&amp;rsquo;s model calls, in order to compile/build the model itself
(whether that means a posterior log probability, in the case of MCMC, or some loss
function to minimize, in the case of VI). By &lt;em>distributions&lt;/em>, I mean the probability
distributions that the random variables in your model can assume (e.g. Normal or
Poisson), and by &lt;em>transformations&lt;/em> I mean deterministic mathematical operations you can
perform on these random variables, while still keeping track of the derivative of these
transformations&lt;sup id="fnref:4">&lt;a href="#fn:4" class="footnote-ref" role="doc-noteref">4&lt;/a>&lt;/sup> (e.g. exponentials, logarithms, sines or cosines).&lt;/p>
&lt;p>This is a good time to point out that the interactions between the language/API and the
distributions and transformations libraries is a major design problem. Here&amp;rsquo;s a (by no
means exhaustive) list of necessary considerations:&lt;/p>
&lt;ol>
&lt;li>In order to build the model density, the framework must keep track of every
distribution and transformation, while also computing the derivatives of any such
transformations. This results in a Jekyll-and-Hyde problem where every transformation
requires a forward and backwards definition. Should this tracking happen eagerly, or
should it be deferred until the user specifies what the model will be used for?&lt;/li>
&lt;li>Theoretically, a model&amp;rsquo;s specification should be the same whether it is to be used
for evaluation, inference or debugging. However, in practice, the program execution
(and computational graph) are different for these three purposes. How should the
framework manage this?&lt;/li>
&lt;li>The framework must also keep track of the shapes of random variables, which is
frighteningly non-trivial! Check out &lt;a href="https://ericmjl.github.io/blog/2019/5/29/reasoning-about-shapes-and-probability-distributions/">this blog
post&lt;/a>
or &lt;a href="https://arxiv.org/abs/1711.10604">the original Tensorflow Distributions paper&lt;/a>
(specifically section 3.3 on shape semantics) for more details.&lt;/li>
&lt;/ol>
&lt;p>For a more comprehensive treatment, I can&amp;rsquo;t recommend &lt;a href="https://docs.google.com/presentation/d/1xgNRJDwkWjTHOYMj5aGefwWiV8x-Tz55GfkBksZsN3g/edit?usp=sharing">Junpeng Lao&amp;rsquo;s PyData Córdoba 2019
talk&lt;/a>
highly enough — he explains in depth the main challenges in implementing a probabilistic
programming API and highlights how various frameworks manage these difficulties.&lt;/p>
&lt;h3 id="computing-the-posterior-inference-algorithm">Computing the posterior: inference algorithm&lt;/h3>
&lt;p>Having specified and built the model, the framework must now actually perform inference:
given a model and some data, obtain the posterior (either by sampling from it, in the
case of MCMC, or by approximating it, in the case of VI).&lt;/p>
&lt;p>Most probabilistic programming frameworks out there implement both MCMC and VI
algorithms, although strength of support and quality of documentation can lean heavily
one way or another. For example, Stan invests heavily into its MCMC, whereas Pyro has
the most extensive support for its stochastic VI.&lt;/p>
&lt;h3 id="computing-the-mode-optimizer">Computing the mode: optimizer&lt;/h3>
&lt;p>Sometimes, instead of performing full-blown inference, it&amp;rsquo;s useful to find the mode of
the model density. These modes can be used as point estimates of parameters, or as the
basis of approximations to a Bayesian posterior. Or perhaps you&amp;rsquo;re doing VI, and you
need some way to perform SGD on a loss function. In either case, a probabilistic
programming framework calls for an optimizer.&lt;/p>
&lt;p>If you don&amp;rsquo;t need to do VI, then a simple and sensible thing to do is to use some
&lt;a href="https://en.wikipedia.org/wiki/Broyden%E2%80%93Fletcher%E2%80%93Goldfarb%E2%80%93Shanno_algorithm">BFGS-based optimization
algorithm&lt;/a>
(e.g. some quasi-Newton method like
&lt;a href="https://en.wikipedia.org/wiki/Limited-memory_BFGS">L-BFGS&lt;/a>) and call it a day.
However, frameworks that focus on VI need to implement &lt;a href="http://docs.pyro.ai/en/stable/optimization.html#module-pyro.optim.optim">optimizers commonly seen in deep
learning&lt;/a>, such
as Adam or RMSProp.&lt;/p>
&lt;h3 id="computing-gradients-autodifferentiation">Computing gradients: autodifferentiation&lt;/h3>
&lt;p>Both the inference algorithm and the optimizer require gradients (at least, if you&amp;rsquo;re
not using ancient inference algorithms and optimizers!), and so you&amp;rsquo;ll need some way to
compute these gradients.&lt;/p>
&lt;p>The easiest thing to do would be to rely on a deep learning framework like TensorFlow or
PyTorch. I&amp;rsquo;ve learned not to get too excited about this though: while deep learning
frameworks&amp;rsquo; heavy optimization of parallelized routines lets you e.g. obtain &lt;a href="https://colindcarroll.com/2019/08/18/very-parallel-mcmc-sampling/">thousands
of MCMC chains in a reasonable amount of
time&lt;/a>, it&amp;rsquo;s not
obvious that this is useful at all (although there&amp;rsquo;s definitely some work going on in
this area).&lt;/p>
&lt;h3 id="monitoring-inference-diagnostics">Monitoring inference: diagnostics&lt;/h3>
&lt;p>Finally, once the inference algorithm has worked its magic, you&amp;rsquo;ll want a way to verify
the validity and efficiency of that inference. This involves some &lt;a href="https://arviz-devs.github.io/arviz/api.html#stats">off-the-shelf
statistical diagnostics&lt;/a> (e.g. BFMI,
information criteria, effective sample size, etc.), but mainly &lt;a href="https://arviz-devs.github.io/arviz/api.html#plots">lots and lots of
visualization&lt;/a>.&lt;/p>
&lt;h2 id="a-zoo-of-probabilistic-programming-frameworks">A Zoo of Probabilistic Programming Frameworks&lt;/h2>
&lt;p>Having outlined the basic internals of probabilistic programming frameworks, I think
it&amp;rsquo;s helpful to go through several of the popular frameworks as examples. I&amp;rsquo;ve tried to
link to the relevant source code in the frameworks where possible.&lt;/p>
&lt;h3 id="stan">Stan&lt;/h3>
&lt;p>It&amp;rsquo;s very easy to describe how Stan is structured: literally everything is
implemented from scratch in C++.&lt;/p>
&lt;ol>
&lt;li>Stan has a compiler for &lt;a href="https://github.com/stan-dev/stan/tree/develop/src/stan/lang">a small domain-specific language for specifying Bayesian
models&lt;/a>&lt;/li>
&lt;li>Stan has libraries of &lt;a href="https://github.com/stan-dev/math/tree/develop/stan/math/prim">probability
distributions&lt;/a> and
&lt;a href="https://github.com/stan-dev/math/tree/develop/stan/math/prim/fun">transforms&lt;/a>&lt;/li>
&lt;li>Stan implements &lt;a href="https://github.com/stan-dev/stan/tree/develop/src/stan/mcmc/hmc">dynamic
HMC&lt;/a> and
&lt;a href="https://github.com/stan-dev/stan/tree/develop/src/stan/variational">variational
inference&lt;/a>&lt;/li>
&lt;li>Stan also rolls their own &lt;a href="https://github.com/stan-dev/math/tree/develop/stan/math">autodifferentiation
library&lt;/a>&lt;sup id="fnref:5">&lt;a href="#fn:5" class="footnote-ref" role="doc-noteref">5&lt;/a>&lt;/sup>&lt;/li>
&lt;li>Stan implements an &lt;a href="https://github.com/stan-dev/stan/tree/develop/src/stan/optimization">L-BFGS based
optimizer&lt;/a> (but
also implements &lt;a href="https://mc-stan.org/docs/2_20/reference-manual/optimization-algorithms-chapter.html">a less efficient Newton
optimizer&lt;/a>)&lt;/li>
&lt;li>Finally, Stan has a &lt;a href="https://github.com/stan-dev/stan/tree/develop/src/stan/analyze/mcmc">suite of
diagnostics&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>Note that contrary to popular belief, Stan &lt;em>does not&lt;/em> implement NUTS:&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">Stan implements a dynamic Hamiltonian Monte Carlo method with multinomial sampling of dynamic length trajectories, generalized termination criterion, and improved adaptation of the Euclidean metric.&lt;/p>&amp;mdash; Dan Simpson (&lt;a href="https://twitter.com/dan_p_simpson">@dan_p_simpson&lt;/a>) &lt;a href="https://twitter.com/dan_p_simpson/status/1037332473175265280">September 5, 2018&lt;/a>&lt;/blockquote>
&lt;p>And in case you&amp;rsquo;re looking for a snazzy buzzword to drop:&lt;/p>
&lt;blockquote class="twitter-tweet">&lt;p lang="en" dir="ltr">Adaptive HMC. &lt;a href="https://twitter.com/betanalpha">@betanalpha&lt;/a> is reluctant to give it a more specific name because, to paraphrase, that’s just marketing bullshit that leads to us celebrating tiny implementation details rather than actual meaningful contributions to comp stats. This is a wide-ranging subtweet.&lt;/p>&amp;mdash; Dan Simpson (&lt;a href="https://twitter.com/dan_p_simpson">@dan_p_simpson&lt;/a>) &lt;a href="https://twitter.com/dan_p_simpson/status/1034098649406554113">August 27, 2018&lt;/a>&lt;/blockquote>
&lt;h3 id="tensorflow-probability-aka-tfp">TensorFlow Probability (a.k.a. TFP)&lt;/h3>
&lt;ol>
&lt;li>TFP users write Python (albeit through an &lt;a href="https://colcarroll.github.io/ppl-api/">extremely verbose
API&lt;/a>)&lt;/li>
&lt;li>TFP implements their own
&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/distributions">distributions&lt;/a>
and
&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/bijectors">transforms&lt;/a>
(which TensorFlow, for some reason, calls &amp;ldquo;bijectors&amp;rdquo;). You can find more details in
&lt;a href="https://arxiv.org/abs/1711.10604">their arXiv paper&lt;/a>&lt;/li>
&lt;li>TFP implements &lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/mcmc">a ton of
MCMC&lt;/a>
algorithms and a handful of &lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/vi">VI
algorithms&lt;/a>
in TensorFlow&lt;/li>
&lt;li>TFP implements &lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/optimizer">several
optimizers&lt;/a>,
including Nelder-Mead, BFGS and L-BFGS (again, in TensorFlow)&lt;/li>
&lt;li>TFP relies on TensorFlow to compute gradients (er, duh)&lt;/li>
&lt;li>TFP implements &lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/mcmc/diagnostic.py">a handful of
metrics&lt;/a>
(e.g. effective sample size and potential scale reduction), but seems to lack a
comprehensive suite of diagnostics and visualizations: even
&lt;a href="https://github.com/tensorflow/probability/tree/master/tensorflow_probability/python/experimental/edward2">Edward2&lt;/a>
(an experimental interface to TFP for flexible modelling, inference and criticism)
suggests that you &lt;a href="https://github.com/tensorflow/probability/blob/master/tensorflow_probability/python/experimental/edward2/Upgrading_From_Edward_To_Edward2.md#model--inference-criticism">build your metrics manually or use boilerplate in
&lt;code>tf.metrics&lt;/code>&lt;/a>&lt;/li>
&lt;/ol>
&lt;h3 id="pymc3">PyMC3&lt;/h3>
&lt;ol>
&lt;li>PyMC3 users write Python code, using a context manager pattern (i.e. &lt;code>with pm.Model as model&lt;/code>)&lt;/li>
&lt;li>PyMC3 implements its own
&lt;a href="https://github.com/pymc-devs/pymc3/tree/master/pymc3/distributions">distributions&lt;/a>
and
&lt;a href="https://github.com/pymc-devs/pymc3/blob/master/pymc3/distributions/transforms.py">transforms&lt;/a>&lt;/li>
&lt;li>PyMC3 implements
&lt;a href="https://github.com/pymc-devs/pymc3/blob/master/pymc3/step_methods/hmc/nuts.py">NUTS&lt;/a>,
(as well as &lt;a href="https://github.com/pymc-devs/pymc3/tree/master/pymc3/step_methods">a range of other MCMC step
methods&lt;/a>) and
&lt;a href="https://github.com/pymc-devs/pymc3/tree/master/pymc3/variational">several variational inference
algorithms&lt;/a>,
although NUTS is the default and recommended inference algorithm&lt;/li>
&lt;li>PyMC3 (specifically, the &lt;code>find_MAP&lt;/code> function) &lt;a href="https://github.com/pymc-devs/pymc3/blob/master/pymc3/tuning/starting.py">relies on
&lt;code>scipy.optimize&lt;/code>&lt;/a>,
which in turn implements a BFGS-based optimizer&lt;/li>
&lt;li>PyMC3 &lt;a href="https://github.com/pymc-devs/pymc3/blob/master/pymc3/theanof.py">relies on
Theano&lt;/a> to compute
gradients&lt;/li>
&lt;li>PyMC3 &lt;a href="https://github.com/pymc-devs/pymc3/blob/master/pymc3/plots/__init__.py">delegates posterior visualization and
diagnostics&lt;/a>
to its cousin project &lt;a href="https://arviz-devs.github.io/arviz/">ArviZ&lt;/a>&lt;/li>
&lt;/ol>
&lt;p>Some remarks:&lt;/p>
&lt;ul>
&lt;li>PyMC3&amp;rsquo;s context manager pattern is an interceptor for sampling statements: essentially
&lt;a href="https://arxiv.org/abs/1811.06150">an accidental implementation of effect handlers&lt;/a>.&lt;/li>
&lt;li>PyMC3&amp;rsquo;s distributions are simpler than those of TFP or PyTorch: they simply need to
have a &lt;code>random&lt;/code> and a &lt;code>logp&lt;/code> method, whereas TFP/PyTorch implement a whole bunch of
other methods to handle shapes, parameterizations, etc. In retrospect, we realize
that this is &lt;a href="https://docs.pymc.io/developer_guide.html#what-we-got-wrong">one of PyMC3&amp;rsquo;s design
flaws&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h3 id="pymc4">PyMC4&lt;/h3>
&lt;p>PyMC4 is still under active development (at least, at the time of writing), but it&amp;rsquo;s
safe to call out the overall architecture.&lt;/p>
&lt;ol>
&lt;li>PyMC4 users will write Python, although now with a generator pattern (e.g. &lt;code>x = yield Normal(0, 1, &amp;quot;x&amp;quot;)&lt;/code>), instead of a context manager&lt;/li>
&lt;li>PyMC4 will &lt;a href="https://github.com/pymc-devs/pymc4/tree/master/pymc4/distributions/">rely on TensorFlow distributions (a.k.a.
&lt;code>tfd&lt;/code>)&lt;/a> for both
distributions and transforms&lt;/li>
&lt;li>PyMC4 will also &lt;a href="https://github.com/pymc-devs/pymc4/tree/master/pymc4/inference/">rely on TensorFlow for
MCMC&lt;/a> (although the
specifics of the exact MCMC algorithm are still fairly fluid at the time of writing)&lt;/li>
&lt;li>As far as I can tell, the optimizer is still TBD&lt;/li>
&lt;li>Because PyMC4 relies on TFP, which relies on TensorFlow, TensorFlow manages all
gradient computations automatically&lt;/li>
&lt;li>Like its predecessor, PyMC4 will delegate diagnostics and visualization to ArviZ&lt;/li>
&lt;/ol>
&lt;p>Some remarks:&lt;/p>
&lt;ul>
&lt;li>With the generator pattern for model specification, PyMC4 embraces the notion of a
probabilistic program as one that defers its computation. For more color on this, see
&lt;a href="https://twitter.com/avibryant/status/1150827954319982592">this Twitter thread&lt;/a> I had
with &lt;a href="https://about.me/avibryant">Avi Bryant&lt;/a>.&lt;/li>
&lt;/ul>
&lt;h3 id="pyro">Pyro&lt;/h3>
&lt;ol>
&lt;li>Pyro users write Python&lt;/li>
&lt;li>Pyro &lt;a href="https://github.com/pyro-ppl/pyro/blob/dev/pyro/distributions/__init__.py">relies on PyTorch
distributions&lt;/a>
(&lt;a href="https://github.com/pyro-ppl/pyro/tree/dev/pyro/distributions">implementing its own where
necessary&lt;/a>), and also
relies on PyTorch distributions &lt;a href="https://github.com/pyro-ppl/pyro/tree/dev/pyro/distributions/transforms">for its
transforms&lt;/a>&lt;/li>
&lt;li>Pyro implements &lt;a href="http://docs.pyro.ai/en/stable/inference.html">many inference
algorithms&lt;/a> in PyTorch (including &lt;a href="https://github.com/pyro-ppl/pyro/tree/dev/pyro/infer/mcmc">HMC
and NUTS&lt;/a>), but support
for &lt;a href="https://github.com/pyro-ppl/pyro/blob/dev/pyro/infer/svi.py">stochastic VI&lt;/a> is
the most extensive&lt;/li>
&lt;li>Pyro implements &lt;a href="https://github.com/pyro-ppl/pyro/blob/master/pyro/optim/optim.py">its own
optimizer&lt;/a> in
PyTorch&lt;/li>
&lt;li>Pyro relies on PyTorch to compute gradients (again, duh)&lt;/li>
&lt;li>As far as I can tell, Pyro doesn&amp;rsquo;t provide any diagnostic or visualization
functionality&lt;/li>
&lt;/ol>
&lt;p>Some remarks:&lt;/p>
&lt;ul>
&lt;li>Pyro includes the Poutine submodule, which is a library of composable &lt;a href="https://arxiv.org/abs/1811.06150">effect
handlers&lt;/a>. While this might sound like recondite
abstractions, they allow you to implement your own custom inference algorithms and
otherwise manipulate Pyro probabilistic programs. In fact, all of Pyro&amp;rsquo;s inference
algorithms use these effect handlers.&lt;/li>
&lt;/ul>
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>In case you&amp;rsquo;re testifying under oath and need more reliable sources than
a blog post, I&amp;rsquo;ve kept a &lt;a href="https://www.zotero.org/eigenfoo/items/collectionKey/AE8882GQ">Zotero
collection&lt;/a> for
this project.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>Universal probabilistic programming is an interesting field of inquiry,
but has mainly remained in the realm of academic research. For a (much) more
comprehensive treatment, check out &lt;a href="http://www.robots.ox.ac.uk/~twgr/assets/pdf/rainforth2017thesis.pdf">Tom Rainforth&amp;rsquo;s PhD
thesis&lt;/a>.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:3" role="doc-endnote">
&lt;p>Since publishing this blog post, I have been informed that I am more
ignorant than I know: I have forgotten
&lt;a href="https://github.com/cscherrer/Soss.jl">Soss.jl&lt;/a> in Julia and
&lt;a href="https://github.com/thu-ml/zhusuan">ZhuSuan&lt;/a> in Python.&amp;#160;&lt;a href="#fnref:3" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:4" role="doc-endnote">
&lt;p>It turns out that such transformations must be &lt;a href="https://en.wikipedia.org/wiki/Local_diffeomorphism">local
diffeomorphisms&lt;/a>, and the
derivative information requires computing the log determinant of the Jacobian
of the transformation, commonly abbreviated to &lt;code>log_det_jac&lt;/code> or something
similar.&amp;#160;&lt;a href="#fnref:4" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:5" role="doc-endnote">
&lt;p>As an aside, I&amp;rsquo;ll say that it&amp;rsquo;s mind boggling how Stan does this. To
quote a (nameless) PyMC core developer:&lt;/p>
&lt;blockquote>
&lt;p>I think that maintaining your own autodifferentiation library is the
path of a crazy person.&lt;/p>
&lt;/blockquote>
&amp;#160;&lt;a href="#fnref:5" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Cookbook — Bayesian Modelling with PyMC3</title><link>https://www.georgeho.org/bayesian-modelling-cookbook/</link><pubDate>Sun, 24 Jun 2018 00:00:00 +0000</pubDate><guid>https://www.georgeho.org/bayesian-modelling-cookbook/</guid><description>&lt;p>Recently I&amp;rsquo;ve started using &lt;a href="https://github.com/pymc-devs/pymc3">PyMC3&lt;/a> for
Bayesian modelling, and it&amp;rsquo;s an amazing piece of software! The API only exposes
as much of heavy machinery of MCMC as you need — by which I mean, just the
&lt;code>pm.sample()&lt;/code> method (a.k.a., as &lt;a href="http://twiecki.github.io/blog/2013/08/12/bayesian-glms-1/">Thomas
Wiecki&lt;/a> puts it, the
&lt;em>Magic Inference Button™&lt;/em>). This really frees up your mind to think about your
data and model, which is really the heart and soul of data science!&lt;/p>
&lt;p>That being said however, I quickly realized that the water gets very deep very
fast: I explored my data set, specified a hierarchical model that made sense to
me, hit the &lt;em>Magic Inference Button™&lt;/em>, and… uh, what now? I blinked at the
angry red warnings the sampler spat out.&lt;/p>
&lt;p>So began by long, rewarding and ongoing exploration of Bayesian modelling. This
is a compilation of notes, tips, tricks and recipes that I&amp;rsquo;ve collected from
everywhere: papers, documentation, peppering my &lt;a href="https://twitter.com/twiecki">more
experienced&lt;/a>
&lt;a href="https://twitter.com/aseyboldt">colleagues&lt;/a> with questions. It&amp;rsquo;s still very much
a work in progress, but hopefully somebody else finds it useful!&lt;/p>
&lt;p>&lt;img src="https://www.georgeho.org/assets/images/pymc-logo.png" alt="PyMC logo">&lt;/p>
&lt;div>
&lt;h2>Contents&lt;/h2>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>&lt;a href="#for-the-uninitiated">For the Uninitiated&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#bayesian-modelling">Bayesian modelling&lt;/a>&lt;/li>
&lt;li>&lt;a href="#markov-chain-monte-carlo">Markov-chain Monte Carlo&lt;/a>&lt;/li>
&lt;li>&lt;a href="#variational-inference">Variational inference&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#model-formulation">Model Formulation&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#hierarchical-models">Hierarchical models&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#model-implementation">Model Implementation&lt;/a>&lt;/li>
&lt;li>&lt;a href="#mcmc-initialization-and-sampling">MCMC Initialization and Sampling&lt;/a>&lt;/li>
&lt;li>&lt;a href="#mcmc-trace-diagnostics">MCMC Trace Diagnostics&lt;/a>
&lt;ul>
&lt;li>&lt;a href="#fixing-divergences">Fixing divergences&lt;/a>&lt;/li>
&lt;li>&lt;a href="#other-common-warnings">Other common warnings&lt;/a>&lt;/li>
&lt;li>&lt;a href="#model-reparameterization">Model reparameterization&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>&lt;a href="#model-diagnostics">Model Diagnostics&lt;/a>&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/div>
&lt;h2 id="for-the-uninitiated">For the Uninitiated&lt;/h2>
&lt;ul>
&lt;li>First of all, &lt;em>welcome!&lt;/em> It&amp;rsquo;s a brave new world out there — where statistics
is cool, Bayesian and (if you&amp;rsquo;re lucky) even easy. Dive in!&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>&lt;strong>EDIT (1/24/2020):&lt;/strong> I published a &lt;a href="https://www.georgeho.org/bayesian-inference-reading/">subsequent blog
post&lt;/a> with a reading list
for Bayesian inference and modelling. Check it out for reading material in
addition to the ones I list below!&lt;/p>
&lt;/blockquote>
&lt;h3 id="bayesian-modelling">Bayesian modelling&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>If you don&amp;rsquo;t know any probability, I&amp;rsquo;d recommend &lt;a href="https://betanalpha.github.io/assets/case_studies/probability_theory.html">Michael
Betancourt&amp;rsquo;s&lt;/a>
crash-course in practical probability theory.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>For an introduction to general Bayesian methods and modelling, I really liked
&lt;a href="http://camdavidsonpilon.github.io/Probabilistic-Programming-and-Bayesian-Methods-for-Hackers/">Cam Davidson Pilon&amp;rsquo;s &lt;em>Bayesian Methods for
Hackers&lt;/em>&lt;/a>:
it really made the whole “thinking like a Bayesian” thing click for me.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you&amp;rsquo;re willing to spend some money, I&amp;rsquo;ve heard that &lt;a href="https://sites.google.com/site/doingbayesiandataanalysis/">&lt;em>Doing Bayesian Data
Analysis&lt;/em> by
Kruschke&lt;/a> (a.k.a.
&lt;em>“the puppy book”&lt;/em>) is for the bucket list.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Here we come to a fork in the road. The central problem in Bayesian modelling
is this: given data and a probabilistic model that we think models this data,
how do we find the posterior distribution of the model&amp;rsquo;s parameters? There are
currently two good solutions to this problem. One is Markov-chain Monte Carlo
sampling (a.k.a. MCMC sampling), and the other is variational inference
(a.k.a. VI). Both methods are mathematical Death Stars: extremely powerful but
incredibly complicated. Nevertheless, I think it&amp;rsquo;s important to get at least a
hand-wavy understanding of what these methods are. If you&amp;rsquo;re new to all this,
my personal recommendation is to invest your time in learning MCMC: it&amp;rsquo;s been
around longer, we know that there are sufficiently robust tools to help you,
and there&amp;rsquo;s a lot more support/documentation out there.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="markov-chain-monte-carlo">Markov-chain Monte Carlo&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>For a good high-level introduction to MCMC, I liked &lt;a href="https://www.youtube.com/watch?v=DJ0c7Bm5Djk&amp;amp;feature=youtu.be&amp;amp;t=4h40m9s">Michael Betancourt&amp;rsquo;s
StanCon 2017
talk&lt;/a>:
especially the first few minutes where he provides a motivation for MCMC, that
really put all this math into context for me.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>For a more in-depth (and mathematical) treatment of MCMC, I&amp;rsquo;d check out his
&lt;a href="https://arxiv.org/abs/1701.02434">paper on Hamiltonian Monte Carlo&lt;/a>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="variational-inference">Variational inference&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>VI has been around for a while, but it was only in 2017 (2 years ago, at the
time of writing) that &lt;em>automatic differentiation variational inference&lt;/em> was
invented. As such, variational inference is undergoing a renaissance and is
currently an active area of statistical research. Since it&amp;rsquo;s such a nascent
field, most resources on it are very theoretical and academic in nature.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Chapter 10 (on approximate inference) in Bishop&amp;rsquo;s &lt;em>Pattern Recognition and
Machine Learning&lt;/em> and &lt;a href="https://www.cs.princeton.edu/courses/archive/fall11/cos597C/lectures/variational-inference-i.pdf">this
tutorial&lt;/a>
by David Blei are excellent, if a bit mathematically-intensive, resources.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The most hands-on explanation of variational inference I&amp;rsquo;ve seen is the docs
for &lt;a href="http://pyro.ai/examples/svi_part_i.html">Pyro&lt;/a>, a probabilistic
programming language developed by Uber that specializes in variational
inference.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="model-formulation">Model Formulation&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Try thinking about &lt;em>how&lt;/em> your data would be generated: what kind of machine
has your data as outputs? This will help you both explore your data, as well
as help you arrive at a reasonable model formulation.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Try to avoid correlated variables. Some of the more robust samplers can cope
with &lt;em>a posteriori&lt;/em> correlated random variables, but sampling is much easier
for everyone involved if the variables are uncorrelated. By the way, the bar
is pretty low here: if the jointplot/scattergram of the two variables looks
like an ellipse, thats usually okay. It&amp;rsquo;s when the ellipse starts looking like
a line that you should be alarmed.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Try to avoid discrete latent variables, and discrete parameters in general.
There is no good method to sample them in a smart way (since discrete
parameters have no gradients); and with “naïve” samplers (i.e. those that do
not take advantage of the gradient), the number of samples one needs to make
good inferences generally scales exponentially in the number of parameters.
For an instance of this, see &lt;a href="https://docs.pymc.io/notebooks/marginalized_gaussian_mixture_model.html">this example on marginal Gaussian
mixtures&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The &lt;a href="https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations">Stan GitHub
wiki&lt;/a> has
some excellent recommendations on how to choose good priors. Once you get a
good handle on the basics of using PyMC3, I &lt;em>100% recommend&lt;/em> reading this wiki
from start to end: the Stan community has fantastic resources on Bayesian
statistics, and even though their APIs are quite different, the mathematical
theory all translates over.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="hierarchical-models">Hierarchical models&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>First of all, hierarchical models can be amazing! &lt;a href="https://docs.pymc.io/notebooks/GLM-hierarchical.html">The PyMC3
docs&lt;/a> opine on this at
length, so let&amp;rsquo;s not waste any digital ink.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>The poster child of a Bayesian hierarchical model looks something like this
(equations taken from
&lt;a href="https://en.wikipedia.org/wiki/Bayesian_hierarchical_modeling">Wikipedia&lt;/a>):&lt;/p>
&lt;p>&lt;img style="float: center"
src="https://wikimedia.org/api/rest_v1/media/math/render/svg/765f37f86fa26bef873048952dccc6e8067b78f4"
alt="Example Bayesian hierarchical model equation #1">&lt;/p>
&lt;p>&lt;img style="float: center"
src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ca8c0e1233fd69fa4325c6eacf8462252ed6b00a"
alt="Example Bayesian hierarchical model equation #2">&lt;/p>
&lt;p>&lt;img style="float: center"
src="https://wikimedia.org/api/rest_v1/media/math/render/svg/1e56b3077b1b3ec867d6a0f2539ba9a3e79b45c1"
alt="Example Bayesian hierarchical model equation #3">&lt;/p>
&lt;p>This hierarchy has 3 levels (some would say it has 2 levels, since there are
only 2 levels of parameters to infer, but honestly whatever: by my count there
are 3). 3 levels is fine, but add any more levels, and it becomes harder for
to sample. Try out a taller hierarchy to see if it works, but err on the side
of 3-level hierarchies.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If your hierarchy is too tall, you can truncate it by introducing a
deterministic function of your parameters somewhere (this usually turns out to
just be a sum). For example, instead of modelling your observations are drawn
from a 4-level hierarchy, maybe your observations can be modeled as the sum of
three parameters, where these parameters are drawn from a 3-level hierarchy.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>More in-depth treatment here in &lt;a href="https://arxiv.org/abs/1312.0906">(Betancourt and Girolami,
2013)&lt;/a>. &lt;strong>tl;dr:&lt;/strong> hierarchical models all
but &lt;em>require&lt;/em> you use to use Hamiltonian Monte Carlo; also included are some
practical tips and goodies on how to do that stuff in the real world.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="model-implementation">Model Implementation&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>At the risk of overgeneralizing, there are only two things that can go wrong
in Bayesian modelling: either your data is wrong, or your model is wrong. And
it is a hell of a lot easier to debug your data than it is to debug your
model. So before you even try implementing your model, plot histograms of your
data, count the number of data points, drop any NaNs, etc. etc.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>PyMC3 has one quirky piece of syntax, which I tripped up on for a while. It&amp;rsquo;s
described quite well in &lt;a href="http://twiecki.github.io/blog/2014/03/17/bayesian-glms-3/#comment-2213376737">this comment on Thomas Wiecki&amp;rsquo;s
blog&lt;/a>.
Basically, suppose you have several groups, and want to initialize several
variables per group, but you want to initialize different numbers of variables
for each group. Then you need to use the quirky &lt;code>variables[index]&lt;/code>
notation. I suggest using &lt;code>scikit-learn&lt;/code>&amp;rsquo;s &lt;code>LabelEncoder&lt;/code> to easily create the
index. For example, to make normally distributed heights for the iris dataset:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Different numbers of examples for each species&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>species &lt;span style="color:#f92672">=&lt;/span> (&lt;span style="color:#ae81ff">48&lt;/span> &lt;span style="color:#f92672">*&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;setosa&amp;#39;&lt;/span>] &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">52&lt;/span> &lt;span style="color:#f92672">*&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;virginica&amp;#39;&lt;/span>] &lt;span style="color:#f92672">+&lt;/span> &lt;span style="color:#ae81ff">63&lt;/span> &lt;span style="color:#f92672">*&lt;/span> [&lt;span style="color:#e6db74">&amp;#39;versicolor&amp;#39;&lt;/span>])
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>num_species &lt;span style="color:#f92672">=&lt;/span> len(list(set(species))) &lt;span style="color:#75715e"># 3&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># One variable per group&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>heights_per_species &lt;span style="color:#f92672">=&lt;/span> pm&lt;span style="color:#f92672">.&lt;/span>Normal(&lt;span style="color:#e6db74">&amp;#39;heights_per_species&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> mu&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>, sd&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>, shape&lt;span style="color:#f92672">=&lt;/span>num_species)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>idx &lt;span style="color:#f92672">=&lt;/span> sklearn&lt;span style="color:#f92672">.&lt;/span>preprocessing&lt;span style="color:#f92672">.&lt;/span>LabelEncoder()&lt;span style="color:#f92672">.&lt;/span>fit_transform(species)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>heights &lt;span style="color:#f92672">=&lt;/span> heights_per_species[idx]
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>You might find yourself in a situation in which you want to use a centered
parameterization for a portion of your data set, but a noncentered
parameterization for the rest of your data set (see below for what these
parameterizations are). There&amp;rsquo;s a useful idiom for you here:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>num_xs &lt;span style="color:#f92672">=&lt;/span> &lt;span style="color:#ae81ff">5&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>use_centered &lt;span style="color:#f92672">=&lt;/span> np&lt;span style="color:#f92672">.&lt;/span>array([&lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>, &lt;span style="color:#ae81ff">0&lt;/span>, &lt;span style="color:#ae81ff">1&lt;/span>]) &lt;span style="color:#75715e"># len(use_centered) = num_xs&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x_sd &lt;span style="color:#f92672">=&lt;/span> pm&lt;span style="color:#f92672">.&lt;/span>HalfCauchy(&lt;span style="color:#e6db74">&amp;#39;x_sd&amp;#39;&lt;/span>, sd&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">1&lt;/span>)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x_raw &lt;span style="color:#f92672">=&lt;/span> pm&lt;span style="color:#f92672">.&lt;/span>Normal(&lt;span style="color:#e6db74">&amp;#39;x_raw&amp;#39;&lt;/span>, mu&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#ae81ff">0&lt;/span>, sd&lt;span style="color:#f92672">=&lt;/span>x_sd&lt;span style="color:#f92672">**&lt;/span>use_centered, shape&lt;span style="color:#f92672">=&lt;/span>num_xs)
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>x &lt;span style="color:#f92672">=&lt;/span> pm&lt;span style="color:#f92672">.&lt;/span>Deterministic(&lt;span style="color:#e6db74">&amp;#39;x&amp;#39;&lt;/span>, x_sd&lt;span style="color:#f92672">**&lt;/span>(&lt;span style="color:#ae81ff">1&lt;/span> &lt;span style="color:#f92672">-&lt;/span> use_centered) &lt;span style="color:#f92672">*&lt;/span> x_raw)
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>You could even experiment with allowing &lt;code>use_centered&lt;/code> to be &lt;em>between&lt;/em> 0 and
1, instead of being &lt;em>either&lt;/em> 0 or 1!&lt;/p>
&lt;/li>
&lt;li>
&lt;p>I prefer to use the &lt;code>pm.Deterministic&lt;/code> function instead of simply using normal
arithmetic operations (e.g. I&amp;rsquo;d prefer to write &lt;code>x = pm.Deterministic('x', y + z)&lt;/code> instead of &lt;code>x = y + z&lt;/code>). This means that you can index the &lt;code>trace&lt;/code> object
later on with just &lt;code>trace['x']&lt;/code>, instead of having to compute it yourself with
&lt;code>trace['y'] + trace['z']&lt;/code>.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="mcmc-initialization-and-sampling">MCMC Initialization and Sampling&lt;/h2>
&lt;ul>
&lt;li>
&lt;p>Have faith in PyMC3&amp;rsquo;s default initialization and sampling settings: someone
much more experienced than us took the time to choose them! NUTS is the most
efficient MCMC sampler known to man, and &lt;code>jitter+adapt_diag&lt;/code>… well, you get
the point.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>However, if you&amp;rsquo;re truly grasping at straws, a more powerful initialization
setting would be &lt;code>advi&lt;/code> or &lt;code>advi+adapt_diag&lt;/code>, which uses variational inference
to initialize the sampler. An even better option would be to use
&lt;code>advi+adapt_diag_grad&lt;/code> &lt;del>which is (at the time of writing) an experimental
feature in beta&lt;/del>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Never initialize the sampler with the MAP estimate! In low dimensional
problems the MAP estimate (a.k.a. the mode of the posterior) is often quite a
reasonable point. But in high dimensions, the MAP becomes very strange. Check
out &lt;a href="http://www.inference.vc/high-dimensional-gaussian-distributions-are-soap-bubble/">Ferenc Huszár&amp;rsquo;s blog
post&lt;/a>
on high-dimensional Gaussians to see why. Besides, at the MAP all the derivatives
of the posterior are zero, and that isn&amp;rsquo;t great for derivative-based samplers.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h2 id="mcmc-trace-diagnostics">MCMC Trace Diagnostics&lt;/h2>
&lt;ul>
&lt;li>You&amp;rsquo;ve hit the &lt;em>Magic Inference Button™&lt;/em>, and you have a &lt;code>trace&lt;/code> object. Now
what? First of all, make sure that your sampler didn&amp;rsquo;t barf itself, and that
your chains are safe for consumption (i.e., analysis).&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>
&lt;p>Theoretically, run the chain for as long as you have the patience or
resources for. In practice, just use the PyMC3 defaults: 500 tuning
iterations, 1000 sampling iterations.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Check for divergences. PyMC3&amp;rsquo;s sampler will spit out a warning if there are
diverging chains, but the following code snippet may make things easier:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>&lt;span style="color:#75715e"># Display the total number and percentage of divergent chains&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>diverging &lt;span style="color:#f92672">=&lt;/span> trace[&lt;span style="color:#e6db74">&amp;#39;diverging&amp;#39;&lt;/span>]
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39;Number of Divergent Chains: &lt;/span>&lt;span style="color:#e6db74">{}&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>format(diverging&lt;span style="color:#f92672">.&lt;/span>nonzero()[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>size))
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>diverging_pct &lt;span style="color:#f92672">=&lt;/span> diverging&lt;span style="color:#f92672">.&lt;/span>nonzero()[&lt;span style="color:#ae81ff">0&lt;/span>]&lt;span style="color:#f92672">.&lt;/span>size &lt;span style="color:#f92672">/&lt;/span> len(trace) &lt;span style="color:#f92672">*&lt;/span> &lt;span style="color:#ae81ff">100&lt;/span>
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span>print(&lt;span style="color:#e6db74">&amp;#39;Percentage of Divergent Chains: &lt;/span>&lt;span style="color:#e6db74">{:.1f}&lt;/span>&lt;span style="color:#e6db74">&amp;#39;&lt;/span>&lt;span style="color:#f92672">.&lt;/span>format(diverging_pct))
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Check the traceplot (&lt;code>pm.traceplot(trace)&lt;/code>). You&amp;rsquo;re looking for traceplots
that look like “fuzzy caterpillars”. If the trace moves into some region and
stays there for a long time (a.k.a. there are some “sticky regions”), that&amp;rsquo;s
cause for concern! That indicates that once the sampler moves into some
region of parameter space, it gets stuck there (probably due to high
curvature or other bad topological properties).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>In addition to the traceplot, there are &lt;a href="https://docs.pymc.io/api/plots.html">a ton of other
plots&lt;/a> you can make with your trace:&lt;/p>
&lt;ul>
&lt;li>&lt;code>pm.plot_posterior(trace)&lt;/code>: check if your posteriors look reasonable.&lt;/li>
&lt;li>&lt;code>pm.forestplot(trace)&lt;/code>: check if your variables have reasonable credible
intervals, and Gelman–Rubin scores close to 1.&lt;/li>
&lt;li>&lt;code>pm.autocorrplot(trace)&lt;/code>: check if your chains are impaired by high
autocorrelation. Also remember that thinning your chains is a waste of
time at best, and deluding yourself at worst. See Chris Fonnesbeck&amp;rsquo;s
comment on &lt;a href="https://github.com/pymc-devs/pymc/issues/23">this GitHub
issue&lt;/a> and &lt;a href="https://twitter.com/junpenglao/status/1009748562136256512">Junpeng Lao&amp;rsquo;s
reply to Michael Betancourt&amp;rsquo;s
tweet&lt;/a>&lt;/li>
&lt;li>&lt;code>pm.energyplot(trace)&lt;/code>: ideally the energy and marginal energy
distributions should look very similar. Long tails in the distribution of
energy levels indicates deteriorated sampler efficiency.&lt;/li>
&lt;li>&lt;code>pm.densityplot(trace)&lt;/code>: a souped-up version of &lt;code>pm.plot_posterior&lt;/code>. It
doesn&amp;rsquo;t seem to be wildly useful unless you&amp;rsquo;re plotting posteriors from
multiple models.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>PyMC3 has a nice helper function to pretty-print a summary table of the
trace: &lt;code>pm.summary(trace)&lt;/code> (I usually tack on a &lt;code>.round(2)&lt;/code> for my sanity).
Look out for:&lt;/p>
&lt;ul>
&lt;li>the $\hat{R}$ values (a.k.a. the Gelman–Rubin statistic, a.k.a. the
potential scale reduction factor, a.k.a. the PSRF): are they all close to
1? If not, something is &lt;em>horribly&lt;/em> wrong. Consider respecifying or
reparameterizing your model. You can also inspect these in the forest plot.&lt;/li>
&lt;li>the sign and magnitude of the inferred values: do they make sense, or are
they unexpected and unreasonable? This could indicate a poorly specified
model. (E.g. parameters of the unexpected sign that have low uncertainties
might indicate that your model needs interaction terms.)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>As a drastic debugging measure, try to &lt;code>pm.sample&lt;/code> with &lt;code>draws=1&lt;/code>,
&lt;code>tune=500&lt;/code>, and &lt;code>discard_tuned_samples=False&lt;/code>, and inspect the traceplot.
During the tuning phase, we don&amp;rsquo;t expect to see friendly fuzzy caterpillars,
but we &lt;em>do&lt;/em> expect to see good (if noisy) exploration of parameter space. So
if the sampler is getting stuck during the tuning phase, that might explain
why the trace looks horrible.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If you get scary errors that describe mathematical problems (e.g. &lt;code>ValueError: Mass matrix contains zeros on the diagonal. Some derivatives might always be zero.&lt;/code>), then you&amp;rsquo;re &lt;del>shit out of luck&lt;/del> exceptionally unlucky: those kinds of
errors are notoriously hard to debug. I can only point to the &lt;a href="http://andrewgelman.com/2008/05/13/the_folk_theore/">Folk Theorem of
Statistical Computing&lt;/a>:&lt;/p>
&lt;blockquote>
&lt;p>If you&amp;rsquo;re having computational problems, probably your model is wrong.&lt;/p>
&lt;/blockquote>
&lt;/li>
&lt;/ol>
&lt;h3 id="fixing-divergences">Fixing divergences&lt;/h3>
&lt;blockquote>
&lt;p>&lt;code>There were N divergences after tuning. Increase 'target_accept' or reparameterize.&lt;/code>&lt;/p>
&lt;p>— The &lt;em>Magic Inference Button™&lt;/em>&lt;/p>
&lt;/blockquote>
&lt;ul>
&lt;li>
&lt;p>Divergences in HMC occur when the sampler finds itself in regions of extremely
high curvature (such as the opening of the a hierarchical funnel). Broadly
speaking, the sampler is prone to malfunction in such regions, causing the
sampler to fly off towards to infinity. The ruins the chains by heavily
biasing the samples.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Remember: if you have even &lt;em>one&lt;/em> diverging chain, you should be worried.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Increase &lt;code>target_accept&lt;/code>: usually 0.9 is a good number (currently the default
in PyMC3 is 0.8). This will help get rid of false positives from the test for
divergences. However, divergences that &lt;em>don&amp;rsquo;t&lt;/em> go away are cause for alarm.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Increasing &lt;code>tune&lt;/code> can sometimes help as well: this gives the sampler more time
to 1) find the typical set and 2) find good values for the step size, mass
matrix elements, etc. If you&amp;rsquo;re running into divergences, it&amp;rsquo;s always possible
that the sampler just hasn&amp;rsquo;t started the mixing phase and is still trying to
find the typical set.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Consider a &lt;em>noncentered&lt;/em> parameterization. This is an amazing trick: it all
boils down to the familiar equation $X = \sigma Z + \mu$ from STAT 101, but
it honestly works wonders. See &lt;a href="http://twiecki.github.io/blog/2017/02/08/bayesian-hierchical-non-centered/">Thomas Wiecki&amp;rsquo;s blog
post&lt;/a>
on it, and &lt;a href="https://docs.pymc.io/notebooks/Diagnosing_biased_Inference_with_Divergences.html">this page from the PyMC3
documentation&lt;/a>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>If that doesn&amp;rsquo;t work, there may be something wrong with the way you&amp;rsquo;re
thinking about your data: consider reparameterizing your model, or
respecifying it entirely.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="other-common-warnings">Other common warnings&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>It&amp;rsquo;s worth noting that far and away the worst warning to get is the one about
divergences. While a divergent chain indicates that your inference may be
flat-out &lt;em>invalid&lt;/em>, the rest of these warnings indicate that your inference is
merely (lol, “merely”) &lt;em>inefficient&lt;/em>.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>It&amp;rsquo;s also worth noting that the &lt;a href="https://mc-stan.org/misc/warnings.html">Brief Guide to Stan&amp;rsquo;s
Warnings&lt;/a> is a tremendous resource for
exactly what kinds of errors you might get when running HMC or NUTS, and how
you should think about them.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;code>The number of effective samples is smaller than XYZ for some parameters.&lt;/code>&lt;/p>
&lt;ul>
&lt;li>Quoting &lt;a href="https://discourse.pymc.io/t/the-number-of-effective-samples-is-smaller-than-25-for-some-parameters/1050/3">Junpeng Lao on
&lt;code>discourse.pymc3.io&lt;/code>&lt;/a>:
“A low number of effective samples is usually an indication of strong
autocorrelation in the chain.”&lt;/li>
&lt;li>Make sure you&amp;rsquo;re using an efficient sampler like NUTS. (And not, for
instance, Gibbs or Metropolis–Hastings.)&lt;/li>
&lt;li>Tweak the acceptance probability (&lt;code>target_accept&lt;/code>) — it should be large
enough to ensure good exploration, but small enough to not reject all
proposals and get stuck.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>The gelman-rubin statistic is larger than XYZ for some parameters. This indicates slight problems during sampling.&lt;/code>&lt;/p>
&lt;ul>
&lt;li>When PyMC3 samples, it runs several chains in parallel. Loosely speaking,
the Gelman–Rubin statistic measures how similar these chains are. Ideally it
should be close to 1.&lt;/li>
&lt;li>Increasing the &lt;code>tune&lt;/code> parameter may help, for the same reasons as described
in the &lt;em>Fixing Divergences&lt;/em> section.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;code>The chain reached the maximum tree depth. Increase max_treedepth, increase target_accept or reparameterize.&lt;/code>&lt;/p>
&lt;ul>
&lt;li>NUTS puts a cap on the depth of the trees that it evaluates during each
iteration, which is controlled through the &lt;code>max_treedepth&lt;/code>. Reaching the
maximum allowable tree depth indicates that NUTS is prematurely pulling the
plug to avoid excessive compute time.&lt;/li>
&lt;li>Yeah, what the &lt;em>Magic Inference Button™&lt;/em> says: try increasing
&lt;code>max_treedepth&lt;/code> or &lt;code>target_accept&lt;/code>.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h3 id="model-reparameterization">Model reparameterization&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>Countless warnings have told you to engage in this strange activity of
“reparameterization”. What even is that? Luckily, the &lt;a href="https://github.com/stan-dev/stan/releases">Stan User
Manual&lt;/a> (specifically the
&lt;em>Reparameterization and Change of Variables&lt;/em> section) has an excellent
explanation of reparameterization, and even some practical tips to help you do
it (although your mileage may vary on how useful those tips will be to you).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Asides from meekly pointing to other resources, there&amp;rsquo;s not much I can do to
help: this stuff really comes from a combination of intuition, statistical
knowledge and good ol&amp;rsquo; experience. I can, however, cite some examples to give
you a better idea.&lt;/p>
&lt;ul>
&lt;li>The noncentered parameterization is a classic example. If you have a
parameter whose mean and variance you are also modelling, the noncentered
parameterization decouples the sampling of mean and variance from the
sampling of the parameter, so that they are now independent. In this way, we
avoid “funnels”.&lt;/li>
&lt;li>The &lt;a href="http://proceedings.mlr.press/v5/carvalho09a.html">&lt;em>horseshoe
distribution&lt;/em>&lt;/a> is known to
be a good shrinkage prior, as it is &lt;em>very&lt;/em> spikey near zero, and has &lt;em>very&lt;/em>
long tails. However, modelling it using one parameter can give multimodal
posteriors — an exceptionally bad result. The trick is to reparameterize and
model it as the product of two parameters: one to create spikiness at zero,
and one to create long tails (which makes sense: to sample from the
horseshoe, take the product of samples from a normal and a half-Cauchy).&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;h2 id="model-diagnostics">Model Diagnostics&lt;/h2>
&lt;ul>
&lt;li>Admittedly the distinction between the previous section and this one is
somewhat artificial (since problems with your chains indicate problems with
your model), but I still think it&amp;rsquo;s useful to make this distinction because
these checks indicate that you&amp;rsquo;re thinking about your data in the wrong way,
(i.e. you made a poor modelling decision), and &lt;em>not&lt;/em> that the sampler is
having a hard time doing its job.&lt;/li>
&lt;/ul>
&lt;ol>
&lt;li>
&lt;p>Run the following snippet of code to inspect the pairplot of your variables
one at a time (if you have a plate of variables, it&amp;rsquo;s fine to pick a couple
at random). It&amp;rsquo;ll tell you if the two random variables are correlated, and
help identify any troublesome neighborhoods in the parameter space (divergent
samples will be colored differently, and will cluster near such
neighborhoods).&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;">&lt;code class="language-python" data-lang="python">&lt;span style="display:flex;">&lt;span>pm&lt;span style="color:#f92672">.&lt;/span>pairplot(trace,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> sub_varnames&lt;span style="color:#f92672">=&lt;/span>[variable_1, variable_2],
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> divergences&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#66d9ef">True&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> color&lt;span style="color:#f92672">=&lt;/span>&lt;span style="color:#e6db74">&amp;#39;C3&amp;#39;&lt;/span>,
&lt;/span>&lt;/span>&lt;span style="display:flex;">&lt;span> kwargs_divergence&lt;span style="color:#f92672">=&lt;/span>{&lt;span style="color:#e6db74">&amp;#39;color&amp;#39;&lt;/span>: &lt;span style="color:#e6db74">&amp;#39;C2&amp;#39;&lt;/span>})
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;/li>
&lt;li>
&lt;p>Look at your posteriors (either from the traceplot, density plots or
posterior plots). Do they even make sense? E.g. are there outliers or long
tails that you weren&amp;rsquo;t expecting? Do their uncertainties look reasonable to
you? If you had &lt;a href="https://en.wikipedia.org/wiki/Plate_notation">a plate&lt;/a> of
variables, are their posteriors different? Did you expect them to be that
way? If not, what about the data made the posteriors different? You&amp;rsquo;re the
only one who knows your problem/use case, so the posteriors better look good
to you!&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Broadly speaking, there are four kinds of bad geometries that your posterior
can suffer from:&lt;/p>
&lt;ul>
&lt;li>highly correlated posteriors: this will probably cause divergences or
traces that don&amp;rsquo;t look like “fuzzy caterpillars”. Either look at the
jointplots of each pair of variables, or look at the correlation matrix of
all variables. Try using a centered parameterization, or reparameterize in
some other way, to remove these correlations.&lt;/li>
&lt;li>posteriors that form “funnels”: this will probably cause divergences. Try
using a noncentered parameterization.&lt;/li>
&lt;li>heavy tailed posteriors: this will probably raise warnings about
&lt;code>max_treedepth&lt;/code> being exceeded. If your data has long tails, you should
model that with a long-tailed distribution. If your data doesn&amp;rsquo;t have long
tails, then your model is ill-specified: perhaps a more informative prior
would help.&lt;/li>
&lt;li>multimodal posteriors: right now this is pretty much a death blow. At the
time of writing, all samplers have a hard time with multimodality, and
there&amp;rsquo;s not much you can do about that. Try reparameterizing to get a
unimodal posterior. If that&amp;rsquo;s not possible (perhaps you&amp;rsquo;re &lt;em>modelling&lt;/em>
multimodality using a mixture model), you&amp;rsquo;re out of luck: just let NUTS
sample for a day or so, and hopefully you&amp;rsquo;ll get a good trace.&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Pick a small subset of your raw data, and see what exactly your model does
with that data (i.e. run the model on a specific subset of your data). I find
that a lot of problems with your model can be found this way.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Run &lt;a href="https://docs.pymc.io/notebooks/posterior_predictive.html">&lt;em>posterior predictive
checks&lt;/em>&lt;/a> (a.k.a.
PPCs): sample from your posterior, plug it back in to your model, and
“generate new data sets”. PyMC3 even has a nice function to do all this for
you: &lt;code>pm.sample_ppc&lt;/code>. But what do you do with these new data sets? That&amp;rsquo;s a
question only you can answer! The point of a PPC is to see if the generated
data sets reproduce patterns you care about in the observed real data set,
and only you know what patterns you care about. E.g. how close are the PPC
means to the observed sample mean? What about the variance?&lt;/p>
&lt;ul>
&lt;li>For example, suppose you were modelling the levels of radon gas in
different counties in a country (through a hierarchical model). Then you
could sample radon gas levels from the posterior for each county, and take
the maximum within each county. You&amp;rsquo;d then have a distribution of maximum
radon gas levels across counties. You could then check if the &lt;em>actual&lt;/em>
maximum radon gas level (in your observed data set) is acceptably within
that distribution. If it&amp;rsquo;s much larger than the maxima, then you would know
that the actual likelihood has longer tails than you assumed (e.g. perhaps
you should use a Student&amp;rsquo;s T instead of a normal?)&lt;/li>
&lt;li>Remember that how well the posterior predictive distribution fits the data
is of little consequence (e.g. the expectation that 90% of the data should
fall within the 90% credible interval of the posterior). The posterior
predictive distribution tells you what values for data you would expect if
we were to remeasure, given that you&amp;rsquo;ve already observed the data you did.
As such, it&amp;rsquo;s informed by your prior as well as your data, and it&amp;rsquo;s not its
job to adequately fit your data!&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol></description></item><item><title>Portfolio Risk Analytics and Performance Attribution with Pyfolio</title><link>https://www.georgeho.org/pyfolio/</link><pubDate>Sat, 16 Dec 2017 00:00:00 +0000</pubDate><guid>https://www.georgeho.org/pyfolio/</guid><description>&lt;p>I was lucky enough to have the chance to intern at
&lt;a href="https://www.quantopian.com/">Quantopian&lt;/a> this summer. During that time I
contributed some exciting stuff to their open-source portfolio analytics engine,
&lt;a href="https://github.com/quantopian/pyfolio">&lt;code>pyfolio&lt;/code>&lt;/a>, and learnt a truckload of
stuff while doing it! In this blog post, I&amp;rsquo;ll describe and walk through two of
the new features that I authored: the risk and performance attribution tear
sheets.&lt;/p>
&lt;center>
&lt;img
src="https://www.georgeho.org/assets/images/pyfolio-logo.png"
alt="Pyfolio logo">
&lt;/center>
&lt;h2 id="risk-analytics">Risk Analytics&lt;/h2>
&lt;p>A well-known truth of algorithmic trading is that it&amp;rsquo;s insufficient to merely
maximize the returns of your algorithm: you must also do so while minimizing the
risk it takes on board. This idea is probably most famously codified in the
&lt;a href="https://en.wikipedia.org/wiki/Sharpe_ratio#Definition">Sharpe ratio&lt;/a>, which
divides by the volatility of the returns stream in order to give a measure of
the “risk-adjusted returns”.&lt;/p>
&lt;p>However, the volatility of returns is a rather poor proxy for the amount of
“risk” that an algorithm takes on. What if our algo loaded all of its money in
the real estate sector? What if the algo shorted extremely large-cap stocks?
What if half of our portfolio is in illiquid, impossible-to-exit positions?&lt;/p>
&lt;p>These are all “risky” behavior for an algorithm to have, and we&amp;rsquo;d like to know
about and understand this kind of behavior before we seriously consider investing
money in the algo. However, these formulations of risk are neither captured nor
quantified by the volatility of returns (as in the Sharpe ratio). Finally,
there is no easy, free, open-source way to get this sort of analysis.&lt;/p>
&lt;p>Enter &lt;code>pyfolio&lt;/code>&amp;rsquo;s new risk tear sheet! It addresses all the problems outlined
above, and more. Let&amp;rsquo;s jump right in with an example.&lt;/p>
&lt;p>&lt;img src="https://www.georgeho.org/assets/images/pyfolio-risk-tear-sheet.png" alt="Example risk tear sheet">&lt;/p>
&lt;p>&lt;em>(Note: this example risk tear sheet came from the &lt;a href="https://github.com/quantopian/pyfolio/pull/391">original pull
request&lt;/a>, and may therefore be
out of date)&lt;/em>&lt;/p>
&lt;p>The first 4 plots show the exposure to common style factors: specifically, the
size of the company (natural log of the market cap), mean reversion (measured
by the &lt;a href="http://www.investopedia.com/terms/m/macd.asp">MACD Signal&lt;/a>), long-term
momentum, and volatility.
A style factor is best explained with examples: mean reversion, momentum,
volatility and the Fama-French canonical factors (SMB, HML, UMD) are all
examples of style factors. They are factors that indicate broad market trends
(instead of being characteristic to individual stocks, like sectors or market
caps) and characterize a particular &lt;em>style&lt;/em> of investing (e.g. mean reversion,
trend-following strategies, etc.).
The analysis is not limited to 4 style factors, though: &lt;code>pyfolio&lt;/code> will handle
as many as you pass in (but see below for a possible complication). As we can
see, the algorithm has a significant exposure to the MACD signal, which may or
may not worry us. For instance, it wouldn&amp;rsquo;t worry us if we knew that it was a
mean-reversion algo, but we would raise some eyebrows if it was something
else… perhaps the author &lt;em>wanted&lt;/em> to write a wonderful, event-driven
sentiment algo, but inadvertently &lt;em>ended up&lt;/em> writing a mean reversion algo!
One important caveat here is that &lt;code>pyfolio&lt;/code> requires you to supply your own
style factors, for every stock in your universe. This is an unfortunately large
complication for the average user, as it would require you to formulate and
implement your own risk model — I explain this in greater detail below.&lt;/p>
&lt;p>The next 3 plots show the exposures to sectors. This first plot shows us how much
the algorithm longed or shorted a specific sector: above the x-axis if it
longed, and below if it shorted. The second plot simply shows the gross exposure
to each sector: taking the absolute value of the positions before normalizing.
The last plot shows the net exposure to each sector: taking the long position
&lt;em>less the short position&lt;/em> before normalizing. This particular algo looks
beautiful: it is equally exposed to all sectors, and not overly exposed to any
one of them. Evidently, this algo must be taking account its sector exposures
in its trading logic: given what we know from above, perhaps it is longing the
top 10 most “mean reverting” stocks in each sector at the start of every
week… This analysis requires no addition data other than your algorithm&amp;rsquo;s
positions: you can supply your own sectors if you like, but if not, the analysis
will default to the &lt;a href="https://www.quantopian.com/help/fundamentals#asset-classification">Morningstar sector
mappings&lt;/a>
(specifically, the &lt;code>morningstar_sector_code&lt;/code> field), available for free on the
Quantopian platform.&lt;/p>
&lt;p>The next 3 plots show the exposures to market caps. In every other respect, it
is identical to the previous 3 plots. These plots look fairly reasonable: most
algos spend most of their positions in large and mega cap names, and have almost
no positions in micro cap stocks. (Quantopian actually discourages investing in
micro cap stocks by pushing users towards using the &lt;a href="https://www.quantopian.com/posts/the-q500us-and-q1500us">Q500 or
Q1500&lt;/a> as a tradeable
universe). This analysis uses &lt;a href="https://www.quantopian.com/help/fundamentals#valuation">Morningstar&amp;rsquo;s &lt;code>market cap&lt;/code>
field&lt;/a>.&lt;/p>
&lt;p>The last 2 plots show the portfolio&amp;rsquo;s exposure to illiquidity (or low trading
volume). This one is a bit trickier to understand: every the end of every day,
we take the number of shares held in each position and divide that by the
total volume. That gives us a number per position per day. We find the 10th
percentile of this number (i.e. the most illiquid) and plot that as a time
series. So it is a measure of how exposed our portfolio is to illiquid stocks.
The first plot shows the illiquid exposure in our long and short positions,
respectively: that is, it takes the number of shares held in each long/short
position, and divides it by the daily total volume. The second plot shows the
gross illiquid exposure, taking the absolute value of positions before
dividing. So it looks like for this particular algo, for the 10% most illiquid
stock in our portfolio, our position accounts for around 0.2–0.6% (&lt;em>not&lt;/em>
0.002–0.006%!) of market volume, on any given day. That&amp;rsquo;s an acceptably low
number! This analysis obviously requires daily volume data per stock, but that&amp;rsquo;s
freely available on Quantopian&amp;rsquo;s platform.&lt;/p>
&lt;p>That&amp;rsquo;s it for the risk tear sheet! There are some more cool ideas in the
works (there always are), such as including plots to show a portfolio&amp;rsquo;s
concentration risk exposure, or a portfolio&amp;rsquo;s exposure to penny stocks. If you
have any suggestions, please file a &lt;a href="https://github.com/quantopian/pyfolio/issues">new GitHub
issue&lt;/a> to let the dev team know!
Pyfolio is open-source and under active development, and outside contributions
are always loved and appreciated. Alternatively, if you just want to find out
more about the nuts and bolts (i.e. the math and the data) that goes into risk
tear sheet, you can dig around &lt;a href="https://github.com/quantopian/pyfolio/tree/master/pyfolio">the source code
itself&lt;/a>!&lt;/p>
&lt;h2 id="risk-models-and-performance-attribution">Risk Models and Performance Attribution&lt;/h2>
&lt;p>There are two things in the discussion of the risk tear sheet that are worth
talking about in further detail:&lt;/p>
&lt;ol>
&lt;li>I mentioned how the computation of style factor exposures (i.e. the first 4
plots) required your own “risk model” (whatever that is), and&lt;/li>
&lt;li>It was nice that we can guess at the inner workings of the algo, just by
seeing its exposure to common factors. E.g., I guessed that the example algo
was a sector-neutral mean reversion algo, because it was equally exposed to
all 11 sectors, and had a high (in magnitude) exposure to the MACD signal.&lt;/li>
&lt;/ol>
&lt;p>I&amp;rsquo;ll talk about both points in order.&lt;/p>
&lt;p>In order to find out your exposure to a style factor, you obviously must first
know how much each stock is affected by the style factor. But how do you get
that? That is what a risk model is for!&lt;/p>
&lt;p>At the end of every period (usually every trading day), the risk model wakes
up, looks at all the pricing data and style factor data for that day.
It then tries to explain as best it can how much each stock was affected by
each style factor. The end result is that each stock will have a couple of
numbers associated with it, one for every style factor. These numbers indicate
how sensitive the stock&amp;rsquo;s returns were to movements in the style factors. These
numbers are called &lt;em>factor loadings&lt;/em> or &lt;em>betas&lt;/em> (although I prefer “factor
loadings” because a lot of things in quant finance are called “beta”).&lt;/p>
&lt;p>Even better, there&amp;rsquo;s no reason why the risk model should limit itself to style
factors! I previously made the distinction between style factors and other
factors such as sectors: theoretically, a risk model should also be able to find
out how sensitive a stock&amp;rsquo;s returns are to movements in its sector: compute a
“sector factor loading”, if you will. Collectively, all the factors that we want
the risk model to consider — be they sector, style or otherwise — are called
&lt;em>common factors&lt;/em>.&lt;/p>
&lt;p>Clearly, having a risk model allows us to do a whole lot of stuff! This is
because, if we want to know how style factors and other prevailing market trends
are affecting our &lt;em>portfolio&lt;/em>, we must first know how they affect the &lt;em>stocks&lt;/em>
in our portfolio. Or, to be a bit more ambitious, if we knew how style factors
and prevailing market trends are impacting our &lt;em>universe&lt;/em> of stocks, then we&amp;rsquo;re
well on the way to knowing how they&amp;rsquo;re impacting our portfolio! The value of
this kind of portfolio analysis should, of course, be self-evident.&lt;/p>
&lt;p>So, suppose we have a risk model. How do we get from a &lt;em>stock-level&lt;/em> understanding
of how market trends are affecting us, to a &lt;em>portfolio-level&lt;/em> understanding of the
same? The answer to this question is called &lt;em>performance attribution&lt;/em>, and is
one of the main reasons a risk model is worth having.&lt;/p>
&lt;p>Instead of prattling on about performance attribution, it&amp;rsquo;d just be easier to
show you the miracles it can do. Below are some (fake, made up) examples of some
analysis performance attribution can give us:&lt;/p>
&lt;p>Date: 08–23–2017&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th style="text-align:left">Factor&lt;/th>
&lt;th style="text-align:right">PnL ($)&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td style="text-align:left">Total PnL&lt;/td>
&lt;td style="text-align:right">-1,000&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Technology&lt;/td>
&lt;td style="text-align:right">70&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Real Estate&lt;/td>
&lt;td style="text-align:right">-40&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Momentum&lt;/td>
&lt;td style="text-align:right">-780&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Mean Reversion&lt;/td>
&lt;td style="text-align:right">100&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Volatility&lt;/td>
&lt;td style="text-align:right">-110&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td style="text-align:left">Stock-Specific&lt;/td>
&lt;td style="text-align:right">480&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>The table shows that today, our algo suffered a $1000 loss, and the breakdown of
that loss indicates that the main culprit is momentum. In other words, our poor
performance today is mostly attributable to the poor performance of the momentum
factor (hence the name, “performance attribution”). The sector factors account
for very little PnL, while the other style factors (mean reversion and
volatility) drive fairly significant profits and losses, but the real smoking
gun here is the fact that momentum completely tanked today.&lt;/p>
&lt;p>There are a few more useful summary statistics that performance attribution can
give us! Traditional computations for the alpha and the Sharpe ratio of a
strategy usually take into account the performance of the market: i.e., the
traditional alpha is a measure of how much our strategy &lt;em>outperformed&lt;/em> the
market, and the traditional Sharpe ratio is a measure of the same, but
accounting for the volatility of returns. These may be dubbed &lt;em>single-factor
alphas&lt;/em>, because they only measure performance once one factor has been
accounted for — namely, the market. In reality, we would like to not only
account for the market, but also any other common factors, such as style or
sector. This leads to the concept of the &lt;em>multi-factor alpha and Sharpe ratio&lt;/em>,
which is exactly the same as the alpha and Sharpe ratio we&amp;rsquo;re familiar with, but
taking into account a lot more factors. In other words, whereas the returns in
excess of the market is quantified by the single factor alpha, the returns in
excess of the market, momentum, mean reversion, volatility etc., is
quantified by the multi factor alpha. The same goes for the single factor and
multi factor Sharpe, in the case of risk-adjusted returns.&lt;/p>
&lt;p>Adding performance attribution capabilities to &lt;code>pyfolio&lt;/code> is an active project! A
couple of pull requests have already been merged to this effect, so definitely
stay tuned! A new version of &lt;code>pyfolio&lt;/code> will probably be made once performance
attribution is up and running. As always, feel free to
&lt;a href="https://github.com/quantopian/pyfolio">contribute to &lt;code>pyfolio&lt;/code>&lt;/a>, be it by
making feature requests, issues with bugs, or submitting a pull request!&lt;/p>
&lt;hr>
&lt;p>&lt;strong>Update (12–16–2017):&lt;/strong> Quantopian recently launched their risk model for anyone to
use! This is a great resource that usually only large and deep-pocketed
financial institutions have access to. Check it out
&lt;a href="https://www.quantopian.com/risk-model">here&lt;/a>!&lt;/p>
&lt;p>&lt;strong>Update (05–11–2018):&lt;/strong> Quantopian&amp;rsquo;s now integrated pyfolio analytics into their
backtest engine! This makes it much easier to see how your algorithm stacks up
against expectations. Check out the announcement
&lt;a href="https://www.quantopian.com/posts/improved-backtest-analysis">here&lt;/a>!&lt;/p>
&lt;p>&lt;strong>Update (05–29–2018):&lt;/strong> Quantopian recently released a white paper on how the risk
model works! Read all about it &lt;a href="https://www.quantopian.com/papers/risk">here&lt;/a>.&lt;/p></description></item></channel></rss>